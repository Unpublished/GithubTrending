[
{"description": "The memory layer for Personalized AI", "language": "Python", "repo": "mem0", "new_stars": 5545, "stars": 18039, "owner": "mem0ai", "forks": 1719},
{"description": "#1 Locally hosted web application that allows you to perform various operations on PDF files", "language": "Java", "repo": "Stirling-PDF", "new_stars": 3649, "stars": 35055, "owner": "Stirling-Tools", "forks": 2603},
{"description": "A one-stop, open-source, high-quality data extraction tool, supports PDF/webpage/e-book extraction.\u4e00\u7ad9\u5f0f\u5f00\u6e90\u9ad8\u8d28\u91cf\u6570\u636e\u63d0\u53d6\u5de5\u5177\uff0c\u652f\u6301PDF/\u7f51\u9875/\u591a\u683c\u5f0f\u7535\u5b50\u4e66\u63d0\u53d6\u3002", "language": "Python", "repo": "MinerU", "new_stars": 1671, "stars": 3250, "owner": "opendatalab", "forks": 244},
{"description": "\ud83d\ude0e Awesome lists about all kinds of interesting topics", "language": null, "repo": "awesome", "new_stars": 2882, "stars": 315127, "owner": "sindresorhus", "forks": 27361},
{"description": "Ollama Python library", "language": "Python", "repo": "ollama-python", "new_stars": 307, "stars": 3225, "owner": "ollama", "forks": 268},
{"description": "Flipper Zero Unleashed Firmware", "language": "C", "repo": "unleashed-firmware", "new_stars": 536, "stars": 16421, "owner": "DarkFlippers", "forks": 1378},
{"description": "NVIDIA Linux open GPU kernel module source", "language": "C", "repo": "open-gpu-kernel-modules", "new_stars": 340, "stars": 14796, "owner": "NVIDIA", "forks": 1209},
{"description": "Find and verify secrets", "language": "Go", "repo": "trufflehog", "new_stars": 188, "stars": 14718, "owner": "trufflesecurity", "forks": 1585},
{"description": "Open source API development ecosystem -", "language": "TypeScript", "repo": "hoppscotch", "new_stars": 865, "stars": 62531, "owner": "hoppscotch", "forks": 4311},
{"description": "Distribute and run LLMs with a single file.", "language": "C++", "repo": "llamafile", "new_stars": 574, "stars": 17889, "owner": "Mozilla-Ocho", "forks": 900},
{"description": "Scripts for fine-tuning Meta Llama3 with composable FSDP & PEFT methods to cover single/multi-node GPUs. Supports default & custom datasets for applications such as summarization and Q&A. Supporting a number of candid inference solutions such as HF TGI, VLLM for local or cloud deployment. Demo apps to showcase Meta Llama3 for WhatsApp & Messenger.", "language": "Jupyter Notebook", "repo": "llama-recipes", "new_stars": 351, "stars": 10906, "owner": "meta-llama", "forks": 1550},
{"description": "NativeLink is an open source high-performance build cache and remote execution server, compatible with Bazel, Buck2, Reclient, and other RBE-compatible build systems. It offers drastically faster builds, reduced test flakiness, and specialized hardware.", "language": "Rust", "repo": "nativelink", "new_stars": 282, "stars": 850, "owner": "TraceMachina", "forks": 92},
{"description": "API Documentation Browser", "language": "Ruby", "repo": "devdocs", "new_stars": 147, "stars": 34497, "owner": "freeCodeCamp", "forks": 2301},
{"description": "AutoMQ is a cloud-first alternative to Kafka by decoupling durability to S3 and EBS. 10x cost-effective. Autoscale in seconds. Single-digit ms latency.", "language": "Java", "repo": "automq", "new_stars": 344, "stars": 2533, "owner": "AutoMQ", "forks": 130},
{"description": "\ud83c\udfa8 Diagram as Code for prototyping cloud system architectures", "language": "Python", "repo": "diagrams", "new_stars": 359, "stars": 36058, "owner": "mingrammer", "forks": 2351},
{"description": "Get up and running with Llama 3.1, Mistral, Gemma 2, and other large language models.", "language": "Go", "repo": "ollama", "new_stars": 2075, "stars": 81791, "owner": "ollama", "forks": 6248}
]