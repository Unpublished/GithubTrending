[
{"description": "Inference code for LLaMA models", "language": "Python", "repo": "llama", "new_stars": 9250, "stars": 33281, "owner": "facebookresearch", "forks": 5171},
{"description": "Generative Models by Stability AI", "language": "Python", "repo": "generative-models", "new_stars": 3154, "stars": 3136, "owner": "Stability-AI", "forks": 578},
{"description": null, "language": "Python", "repo": "chatgpt-retrieval", "new_stars": 684, "stars": 936, "owner": "techleadhd", "forks": 436},
{"description": "A high-throughput and memory-efficient inference and serving engine for LLMs", "language": "Python", "repo": "vllm", "new_stars": 2413, "stars": 3936, "owner": "vllm-project", "forks": 374},
{"description": "Private Q&A and summarization of documents+images or chat with local GPT, 100% private, Apache 2.0. Supports LLaMa2, llama.cpp, and more. Demo:", "language": "Python", "repo": "h2ogpt", "new_stars": 2888, "stars": 5754, "owner": "h2oai", "forks": 661},
{"description": "You like pytorch? You like micrograd? You love tinygrad!", "language": "Python", "repo": "tinygrad", "new_stars": 3949, "stars": 18220, "owner": "tinygrad", "forks": 2318},
{"description": "Fine-tuning ChatGLM-6B with PEFT | \u57fa\u4e8e PEFT \u7684\u9ad8\u6548 ChatGLM \u5fae\u8c03", "language": "Python", "repo": "ChatGLM-Efficient-Tuning", "new_stars": 1105, "stars": 2434, "owner": "hiyouga", "forks": 347},
{"description": "Fast and memory-efficient exact attention", "language": "Python", "repo": "flash-attention", "new_stars": 1676, "stars": 5412, "owner": "Dao-AILab", "forks": 431},
{"description": "Large-scale Self-supervised Pre-training Across Tasks, Languages, and Modalities", "language": "Python", "repo": "unilm", "new_stars": 1627, "stars": 14440, "owner": "microsoft", "forks": 2021},
{"description": "A powerful and modular stable diffusion GUI with a graph/nodes interface.", "language": "Python", "repo": "ComfyUI", "new_stars": 1816, "stars": 8042, "owner": "comfyanonymous", "forks": 713},
{"description": "Voice data <= 10 mins can also be used to train a good VC model!", "language": "Python", "repo": "Retrieval-based-Voice-Conversion-WebUI", "new_stars": 2768, "stars": 8135, "owner": "RVC-Project", "forks": 1190},
{"description": "[PREVIEW] Sample code for a simple web chat experience targeting chatGPT through AOAI.", "language": "Python", "repo": "sample-app-aoai-chatGPT", "new_stars": 112, "stars": 282, "owner": "microsoft", "forks": 253},
{"description": "\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u30dc\u30a4\u30b9\u30c1\u30a7\u30f3\u30b8\u30e3\u30fc Realtime Voice Changer", "language": "Python", "repo": "voice-changer", "new_stars": 3083, "stars": 8194, "owner": "w-okada", "forks": 933},
{"description": "WebGLM: An Efficient Web-enhanced Question Answering System (KDD 2023)", "language": "Python", "repo": "WebGLM", "new_stars": 727, "stars": 1172, "owner": "THUDM", "forks": 113},
{"description": "Official Code for DragGAN (SIGGRAPH 2023)", "language": "Python", "repo": "DragGAN", "new_stars": 15217, "stars": 31274, "owner": "XingangPan", "forks": 3436},
{"description": "Fast Segment Anything", "language": "Python", "repo": "FastSAM", "new_stars": 4894, "stars": 4952, "owner": "CASIA-IVA-Lab", "forks": 791},
{"description": "aider is GPT powered coding in your terminal", "language": "Python", "repo": "aider", "new_stars": 2082, "stars": 2544, "owner": "paul-gauthier", "forks": 426},
{"description": "Unified AI", "language": "Python", "repo": "ivy", "new_stars": 904, "stars": 12175, "owner": "unifyai", "forks": 4803},
{"description": "Hey there new grad", "language": "Python", "repo": "New-Grad-2024", "new_stars": 1098, "stars": 2139, "owner": "ReaVNaiL", "forks": 119},
{"description": "Train neural networks up to 7x faster", "language": "Python", "repo": "composer", "new_stars": 845, "stars": 4414, "owner": "mosaicml", "forks": 331},
{"description": "[CVPR 2023 Best Paper] Planning-oriented Autonomous Driving", "language": "Python", "repo": "UniAD", "new_stars": 1046, "stars": 1996, "owner": "OpenDriveLab", "forks": 229},
{"description": "Run large language models at home, BitTorrent-style. Fine-tuning and inference up to 10x faster than offloading", "language": "Python", "repo": "petals", "new_stars": 1276, "stars": 6219, "owner": "bigscience-workshop", "forks": 272},
{"description": "The official GitHub page for the survey paper \"A Survey of Large Language Models\".", "language": "Python", "repo": "LLMSurvey", "new_stars": 1999, "stars": 4347, "owner": "RUCAIBox", "forks": 333},
{"description": "Official PyTorch implementation of StyleGAN3", "language": "Python", "repo": "stylegan3", "new_stars": 438, "stars": 5678, "owner": "NVlabs", "forks": 996},
{"description": "Data validation using Python type hints", "language": "Python", "repo": "pydantic", "new_stars": 681, "stars": 14883, "owner": "pydantic", "forks": 1328}
]