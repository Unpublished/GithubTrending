[
{"description": "An AI coding engine for building complex, real-world software with LLMs", "language": "Go", "repo": "plandex", "new_stars": 8754, "stars": 8943, "owner": "plandex-ai", "forks": 668},
{"description": "A complete computer science study plan to become a software engineer.", "language": null, "repo": "coding-interview-university", "new_stars": 10580, "stars": 290994, "owner": "jwasham", "forks": 73729},
{"description": "RAGFlow is an open-source RAG (Retrieval-Augmented Generation) engine based on deep document understanding.", "language": "Python", "repo": "ragflow", "new_stars": 5040, "stars": 6328, "owner": "infiniflow", "forks": 531},
{"description": "Vue3 + Pinia + Vite5 \u4eff\u6296\u97f3\uff0cVue \u5728\u79fb\u52a8\u7aef\u7684\u6700\u4f73\u5b9e\u8df5 . Imitate TikTok \uff0cVue Best practices on Mobile", "language": "Vue", "repo": "douyin", "new_stars": 5020, "stars": 6599, "owner": "zyronon", "forks": 1627},
{"description": "Instant voice cloning by MyShell.", "language": "Python", "repo": "OpenVoice", "new_stars": 6964, "stars": 23585, "owner": "myshell-ai", "forks": 2166},
{"description": "Dify is an open-source LLM app development platform. Dify's intuitive interface combines AI workflow, RAG pipeline, agent capabilities, model management, observability features and more, letting you quickly go from prototype to production.", "language": "TypeScript", "repo": "dify", "new_stars": 7335, "stars": 26200, "owner": "langgenius", "forks": 3445},
{"description": "SWE-agent takes a GitHub issue and tries to automatically fix it, using GPT-4, or your LM of choice. It solves 12.29% of bugs in the SWE-bench evaluation set and takes just 1.5 minutes to run.", "language": "Python", "repo": "SWE-agent", "new_stars": 7303, "stars": 10144, "owner": "princeton-nlp", "forks": 979},
{"description": "Llama\u4e2d\u6587\u793e\u533a\uff0cLlama3\u5728\u7ebf\u4f53\u9a8c\u548c\u5fae\u8c03\u6a21\u578b\u5df2\u5f00\u653e\uff0c\u5b9e\u65f6\u6c47\u603b\u6700\u65b0Llama3\u5b66\u4e60\u8d44\u6599\uff0c\u5df2\u5c06\u6240\u6709\u4ee3\u7801\u66f4\u65b0\u9002\u914dLlama3\uff0c\u6784\u5efa\u6700\u597d\u7684\u4e2d\u6587Llama\u5927\u6a21\u578b\uff0c\u5b8c\u5168\u5f00\u6e90\u53ef\u5546\u7528", "language": "Python", "repo": "Llama-Chinese", "new_stars": 2417, "stars": 11443, "owner": "LlamaFamily", "forks": 1071},
{"description": "Unify Efficient Fine-Tuning of 100+ LLMs", "language": "Python", "repo": "LLaMA-Factory", "new_stars": 5466, "stars": 20859, "owner": "hiyouga", "forks": 2503},
{"description": "\u8ba1\u7b97\u673a\u81ea\u5b66\u6307\u5357", "language": "HTML", "repo": "cs-self-learning", "new_stars": 6063, "stars": 50112, "owner": "PKUFlyingPig", "forks": 6224},
{"description": "OpenUI let's you describe UI using your imagination, then see it rendered live.", "language": "TypeScript", "repo": "openui", "new_stars": 3842, "stars": 6452, "owner": "wandb", "forks": 576},
{"description": "\ud83d\udc41\u200d\ud83d\udde8 Rare and exotic sats", "language": "Rust", "repo": "ord", "new_stars": 492, "stars": 3655, "owner": "ordinals", "forks": 1244},
{"description": "Get up and running with Llama 3, Mistral, Gemma, and other large language models.", "language": "Go", "repo": "ollama", "new_stars": 11056, "stars": 63436, "owner": "ollama", "forks": 4554},
{"description": "LLocalSearch is a completely locally running search aggregator using LLM Agents. The user can ask a question and the system will use a chain of LLMs to find the answer. The user can see the progress of the agents and the final answer. No OpenAI or Google API keys are needed.", "language": "Go", "repo": "LLocalSearch", "new_stars": 4917, "stars": 5022, "owner": "nilsherzig", "forks": 315},
{"description": "An open-source & self-hostable Heroku / Netlify / Vercel alternative.", "language": "PHP", "repo": "coolify", "new_stars": 3107, "stars": 15095, "owner": "coollabsio", "forks": 822},
{"description": "\ud83d\ude80 KIMI AI \u957f\u6587\u672c\u5927\u6a21\u578b\u9006\u5411API\u767d\u5ad6\u6d4b\u8bd5\u3010\u7279\u957f\uff1a\u957f\u6587\u672c\u89e3\u8bfb\u6574\u7406\u3011\uff0c\u652f\u6301\u9ad8\u901f\u6d41\u5f0f\u8f93\u51fa\u3001\u667a\u80fd\u4f53\u5bf9\u8bdd\u3001\u8054\u7f51\u641c\u7d22\u3001\u957f\u6587\u6863\u89e3\u8bfb\u3001\u56fe\u50cf\u89e3\u6790\u3001\u591a\u8f6e\u5bf9\u8bdd\uff0c\u96f6\u914d\u7f6e\u90e8\u7f72\uff0c\u591a\u8deftoken\u652f\u6301\uff0c\u81ea\u52a8\u6e05\u7406\u4f1a\u8bdd\u75d5\u8ff9\u3002", "language": "TypeScript", "repo": "kimi-free-api", "new_stars": 1522, "stars": 2518, "owner": "LLM-Red-Team", "forks": 358},
{"description": "30 days of Python programming challenge is a step-by-step guide to learn the Python programming language in 30 days. This challenge may take more than100 days, follow your own pace. These videos may help too:", "language": "Python", "repo": "30-Days-Of-Python", "new_stars": 1931, "stars": 31899, "owner": "Asabeneh", "forks": 6495},
{"description": "Utilize the unlimited free GPT-3.5-Turbo API service provided by the login-free ChatGPT Web.", "language": "JavaScript", "repo": "FreeGPT35", "new_stars": 2307, "stars": 3011, "owner": "missuo", "forks": 909},
{"description": "\u26d3\ufe0f Langflow is a dynamic graph where each node is an executable unit. Its modular and interactive design fosters rapid experimentation and prototyping, pushing hard on the limits of creativity.", "language": "JavaScript", "repo": "langflow", "new_stars": 2251, "stars": 17557, "owner": "langflow-ai", "forks": 2609},
{"description": "Finetune Llama 3, Mistral & Gemma LLMs 2-5x faster with 80% less memory", "language": "Python", "repo": "unsloth", "new_stars": 3097, "stars": 8397, "owner": "unslothai", "forks": 530},
{"description": "Inference Llama 2 in one file of pure C", "language": "C", "repo": "llama2.c", "new_stars": 1274, "stars": 16034, "owner": "karpathy", "forks": 1826},
{"description": "Distribute and run LLMs with a single file.", "language": "C++", "repo": "llamafile", "new_stars": 3133, "stars": 14983, "owner": "Mozilla-Ocho", "forks": 741},
{"description": "Scripts for fine-tuning Meta Llama3 with composable FSDP & PEFT methods to cover single/multi-node GPUs. Supports default & custom datasets for applications such as summarization and Q&A. Supporting a number of candid inference solutions such as HF TGI, VLLM for local or cloud deployment. Demo apps to showcase Meta Llama3 for WhatsApp & Messenger.", "language": "Jupyter Notebook", "repo": "llama-recipes", "new_stars": 1288, "stars": 9385, "owner": "meta-llama", "forks": 1315},
{"description": "Question and Answer based on Anything.", "language": "Python", "repo": "QAnything", "new_stars": 2820, "stars": 8976, "owner": "netease-youdao", "forks": 841},
{"description": "A Native-PyTorch Library for LLM Fine-tuning", "language": "Python", "repo": "torchtune", "new_stars": 2271, "stars": 2996, "owner": "pytorch", "forks": 197}
]