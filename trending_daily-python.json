[
{"description": "Inference code for LLaMA models", "language": "Python", "repo": "llama", "new_stars": 1352, "stars": 32007, "owner": "facebookresearch", "forks": 4999},
{"description": "Advanced Python Mastery (course by", "language": "Python", "repo": "python-mastery", "new_stars": 2373, "stars": 5595, "owner": "dabeaz-course", "forks": 635},
{"description": "Examples and recipes for Llama 2 model", "language": "Python", "repo": "llama-recipes", "new_stars": 431, "stars": 1223, "owner": "facebookresearch", "forks": 121},
{"description": null, "language": "Python", "repo": "NeuralHaircut", "new_stars": 45, "stars": 264, "owner": "SamsungLabs", "forks": 25},
{"description": "Large-scale Self-supervised Pre-training Across Tasks, Languages, and Modalities", "language": "Python", "repo": "unilm", "new_stars": 90, "stars": 14324, "owner": "microsoft", "forks": 2016},
{"description": "Open source implementation of the ChatGPT Code Interpreter", "language": "Python", "repo": "codeinterpreter-api", "new_stars": 305, "stars": 1527, "owner": "shroominic", "forks": 128},
{"description": "low-cost, high-efficiency, easy-to-implement", "language": "Python", "repo": "c-binance-future-quant", "new_stars": 23, "stars": 237, "owner": "Melelery", "forks": 159},
{"description": "\u5927\u9ea6\u7f51\u62a2\u7968\u811a\u672c", "language": "Python", "repo": "Automatic_ticket_purchase", "new_stars": 31, "stars": 2074, "owner": "MakiNaruto", "forks": 484},
{"description": "Repo for adapting Meta LlaMA2 in Chinese! META\u6700\u65b0\u53d1\u5e03\u7684LlaMA2\u7684\u6c49\u5316\u7248\uff01 \uff08\u5b8c\u5168\u5f00\u6e90\u53ef\u5546\u7528\uff09", "language": "Python", "repo": "Chinese-LlaMA2", "new_stars": 64, "stars": 307, "owner": "michael-wzhu", "forks": 11},
{"description": "LLaMA v2 Chatbot", "language": "Python", "repo": "llama2-chatbot", "new_stars": 189, "stars": 687, "owner": "a16z-infra", "forks": 96},
{"description": "A gradio web UI for running Large Language Models like LLaMA, llama.cpp, GPT-J, Pythia, OPT, and GALACTICA.", "language": "Python", "repo": "text-generation-webui", "new_stars": 252, "stars": 18443, "owner": "oobabooga", "forks": 2347},
{"description": "ShortGPT - An experimental AI framework for automated short/video content creation. Enables creators to rapidly produce, manage, and deliver content using AI and automation.", "language": "Python", "repo": "ShortGPT", "new_stars": 269, "stars": 1335, "owner": "RayVentura", "forks": 118},
{"description": "Practical Python Programming (course by", "language": "Python", "repo": "practical-python", "new_stars": 84, "stars": 8902, "owner": "dabeaz-course", "forks": 5467},
{"description": "Hey there new grad", "language": "Python", "repo": "New-Grad-2024", "new_stars": 41, "stars": 2101, "owner": "ReaVNaiL", "forks": 115},
{"description": "Diagram as Code for prototyping cloud system architectures", "language": "Python", "repo": "diagrams", "new_stars": 133, "stars": 30724, "owner": "mingrammer", "forks": 1961},
{"description": "Implementation of the LLaMA language model based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed.", "language": "Python", "repo": "lit-llama", "new_stars": 8, "stars": 4901, "owner": "Lightning-AI", "forks": 393},
{"description": "\u4e2d\u6587LLaMA&Alpaca\u5927\u8bed\u8a00\u6a21\u578b+\u672c\u5730CPU/GPU\u8bad\u7ec3\u90e8\u7f72 (Chinese LLaMA & Alpaca LLMs)", "language": "Python", "repo": "Chinese-LLaMA-Alpaca", "new_stars": 90, "stars": 13001, "owner": "ymcui", "forks": 1369},
{"description": "Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.", "language": "Python", "repo": "transformers", "new_stars": 183, "stars": 108416, "owner": "huggingface", "forks": 21538},
{"description": "LLaMA Cog template", "language": "Python", "repo": "cog-llama-template", "new_stars": 16, "stars": 175, "owner": "a16z-infra", "forks": 13},
{"description": "Building applications with LLMs through composability", "language": "Python", "repo": "langchain", "new_stars": 176, "stars": 55660, "owner": "hwchase17", "forks": 7241},
{"description": null, "language": "Python", "repo": "webdriver_manager", "new_stars": 3, "stars": 1414, "owner": "SergeyPirogov", "forks": 323},
{"description": "Firefly(\u6d41\u8424): \u4e2d\u6587\u5bf9\u8bdd\u5f0f\u5927\u8bed\u8a00\u6a21\u578b(\u5168\u91cf\u5fae\u8c03+QLoRA)\uff0c\u652f\u6301\u5fae\u8c03Llma2\u3001Llama\u3001Baichuan\u3001InternLM\u3001Ziya\u3001Bloom\u7b49\u5927\u6a21\u578b", "language": "Python", "repo": "Firefly", "new_stars": 40, "stars": 1131, "owner": "yangjianxin1", "forks": 87},
{"description": "An open platform for training, serving, and evaluating large language models. Release repo for Vicuna and FastChat-T5.", "language": "Python", "repo": "FastChat", "new_stars": 59, "stars": 25274, "owner": "lm-sys", "forks": 2970},
{"description": "Uses Various AI Service APIs to generate memes with text and images", "language": "Python", "repo": "Full-Stack-AI-Meme-Generator", "new_stars": 30, "stars": 132, "owner": "ThioJoe", "forks": 14},
{"description": "Run large language models at home, BitTorrent-style. Fine-tuning and inference up to 10x faster than offloading", "language": "Python", "repo": "petals", "new_stars": 180, "stars": 6019, "owner": "bigscience-workshop", "forks": 259}
]