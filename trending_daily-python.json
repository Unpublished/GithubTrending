[
{"description": "Inference code for LLaMA models", "language": "Python", "repo": "llama", "new_stars": 1352, "stars": 32616, "owner": "facebookresearch", "forks": 5052},
{"description": "Advanced Python Mastery (course by", "language": "Python", "repo": "python-mastery", "new_stars": 2373, "stars": 5808, "owner": "dabeaz-course", "forks": 659},
{"description": "Examples and recipes for Llama 2 model", "language": "Python", "repo": "llama-recipes", "new_stars": 431, "stars": 1325, "owner": "facebookresearch", "forks": 129},
{"description": null, "language": "Python", "repo": "NeuralHaircut", "new_stars": 45, "stars": 314, "owner": "SamsungLabs", "forks": 28},
{"description": "Large-scale Self-supervised Pre-training Across Tasks, Languages, and Modalities", "language": "Python", "repo": "unilm", "new_stars": 90, "stars": 14377, "owner": "microsoft", "forks": 2017},
{"description": "Open source implementation of the ChatGPT Code Interpreter", "language": "Python", "repo": "codeinterpreter-api", "new_stars": 305, "stars": 1593, "owner": "shroominic", "forks": 134},
{"description": "low-cost, high-efficiency, easy-to-implement", "language": "Python", "repo": "c-binance-future-quant", "new_stars": 23, "stars": 270, "owner": "Melelery", "forks": 171},
{"description": "\u5927\u9ea6\u7f51\u62a2\u7968\u811a\u672c", "language": "Python", "repo": "Automatic_ticket_purchase", "new_stars": 31, "stars": 2111, "owner": "MakiNaruto", "forks": 490},
{"description": "Repo for adapting Meta LlaMA2 in Chinese! META\u6700\u65b0\u53d1\u5e03\u7684LlaMA2\u7684\u6c49\u5316\u7248\uff01 \uff08\u5b8c\u5168\u5f00\u6e90\u53ef\u5546\u7528\uff09", "language": "Python", "repo": "Chinese-LlaMA2", "new_stars": 64, "stars": 340, "owner": "michael-wzhu", "forks": 13},
{"description": "LLaMA v2 Chatbot", "language": "Python", "repo": "llama2-chatbot", "new_stars": 189, "stars": 725, "owner": "a16z-infra", "forks": 97},
{"description": "A gradio web UI for running Large Language Models like LLaMA, llama.cpp, GPT-J, Pythia, OPT, and GALACTICA.", "language": "Python", "repo": "text-generation-webui", "new_stars": 252, "stars": 18519, "owner": "oobabooga", "forks": 2360},
{"description": "ShortGPT - An experimental AI framework for automated short/video content creation. Enables creators to rapidly produce, manage, and deliver content using AI and automation.", "language": "Python", "repo": "ShortGPT", "new_stars": 269, "stars": 1378, "owner": "RayVentura", "forks": 126},
{"description": "Practical Python Programming (course by", "language": "Python", "repo": "practical-python", "new_stars": 84, "stars": 8916, "owner": "dabeaz-course", "forks": 5473},
{"description": "Hey there new grad", "language": "Python", "repo": "New-Grad-2024", "new_stars": 41, "stars": 2110, "owner": "ReaVNaiL", "forks": 115},
{"description": "Diagram as Code for prototyping cloud system architectures", "language": "Python", "repo": "diagrams", "new_stars": 133, "stars": 30746, "owner": "mingrammer", "forks": 1962},
{"description": "Implementation of the LLaMA language model based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed.", "language": "Python", "repo": "lit-llama", "new_stars": 8, "stars": 4908, "owner": "Lightning-AI", "forks": 393},
{"description": "\u4e2d\u6587LLaMA&Alpaca\u5927\u8bed\u8a00\u6a21\u578b+\u672c\u5730CPU/GPU\u8bad\u7ec3\u90e8\u7f72 (Chinese LLaMA & Alpaca LLMs)", "language": "Python", "repo": "Chinese-LLaMA-Alpaca", "new_stars": 90, "stars": 13034, "owner": "ymcui", "forks": 1371},
{"description": "Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.", "language": "Python", "repo": "transformers", "new_stars": 183, "stars": 108460, "owner": "huggingface", "forks": 21546},
{"description": "LLaMA Cog template", "language": "Python", "repo": "cog-llama-template", "new_stars": 16, "stars": 178, "owner": "a16z-infra", "forks": 13},
{"description": "Building applications with LLMs through composability", "language": "Python", "repo": "langchain", "new_stars": 176, "stars": 55705, "owner": "hwchase17", "forks": 7246},
{"description": null, "language": "Python", "repo": "webdriver_manager", "new_stars": 3, "stars": 1415, "owner": "SergeyPirogov", "forks": 323},
{"description": "Firefly(\u6d41\u8424): \u4e2d\u6587\u5bf9\u8bdd\u5f0f\u5927\u8bed\u8a00\u6a21\u578b(\u5168\u91cf\u5fae\u8c03+QLoRA)\uff0c\u652f\u6301\u5fae\u8c03Llma2\u3001Llama\u3001Baichuan\u3001InternLM\u3001Ziya\u3001Bloom\u7b49\u5927\u6a21\u578b", "language": "Python", "repo": "Firefly", "new_stars": 40, "stars": 1143, "owner": "yangjianxin1", "forks": 88},
{"description": "An open platform for training, serving, and evaluating large language models. Release repo for Vicuna and Chatbot Arena.", "language": "Python", "repo": "FastChat", "new_stars": 59, "stars": 25286, "owner": "lm-sys", "forks": 2971},
{"description": "Uses Various AI Service APIs to generate memes with text and images", "language": "Python", "repo": "Full-Stack-AI-Meme-Generator", "new_stars": 30, "stars": 136, "owner": "ThioJoe", "forks": 14},
{"description": "Run large language models at home, BitTorrent-style. Fine-tuning and inference up to 10x faster than offloading", "language": "Python", "repo": "petals", "new_stars": 180, "stars": 6059, "owner": "bigscience-workshop", "forks": 263}
]