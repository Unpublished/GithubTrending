[
{"description": "gpt4all: an ecosystem of open-source chatbots trained on a massive collections of clean assistant data including code, stories and dialogue", "language": "Python", "repo": "gpt4all", "new_stars": 12941, "stars": 24025, "owner": "nomic-ai", "forks": 2431},
{"description": "\u79d1\u7814\u5de5\u4f5c\u4e13\u7528ChatGPT\u62d3\u5c55\uff0c\u7279\u522b\u4f18\u5316\u5b66\u672fPaper\u6da6\u8272\u4f53\u9a8c\uff0c\u652f\u6301\u81ea\u5b9a\u4e49\u5feb\u6377\u6309\u94ae\uff0c\u652f\u6301\u81ea\u5b9a\u4e49\u51fd\u6570\u63d2\u4ef6\uff0c\u652f\u6301markdown\u8868\u683c\u663e\u793a\uff0cTex\u516c\u5f0f\u53cc\u663e\u793a\uff0c\u4ee3\u7801\u663e\u793a\u529f\u80fd\u5b8c\u5584\uff0c\u65b0\u589e\u672c\u5730Python/C++/Go\u9879\u76ee\u6811\u5256\u6790\u529f\u80fd/\u9879\u76ee\u6e90\u4ee3\u7801\u81ea\u8bd1\u89e3\u80fd\u529b\uff0c\u65b0\u589ePDF\u548cWord\u6587\u732e\u6279\u91cf\u603b\u7ed3\u529f\u80fd/PDF\u8bba\u6587\u5168\u6587\u7ffb\u8bd1\u529f\u80fd", "language": "Python", "repo": "chatgpt_academic", "new_stars": 9476, "stars": 23290, "owner": "binary-husky", "forks": 2563},
{"description": "Fine-tuning LLaMA to follow instructions within 1 Hour and 1.2M Parameters", "language": "Python", "repo": "LLaMA-Adapter", "new_stars": 1156, "stars": 1994, "owner": "ZrrSkywalker", "forks": 118},
{"description": "Build and control your own LLMs", "language": "Python", "repo": "xturing", "new_stars": 776, "stars": 1211, "owner": "stochasticai", "forks": 80},
{"description": "Making large AI models cheaper, faster and more accessible", "language": "Python", "repo": "ColossalAI", "new_stars": 4023, "stars": 27147, "owner": "hpcaitech", "forks": 3086},
{"description": "Building applications with LLMs through composability", "language": "Python", "repo": "langchain", "new_stars": 3728, "stars": 22215, "owner": "hwchase17", "forks": 2040},
{"description": "An open-source framework for training large multimodal models", "language": "Python", "repo": "open_flamingo", "new_stars": 501, "stars": 1495, "owner": "mlfoundations", "forks": 86},
{"description": "Implementation of the LLaMA language model based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed.", "language": "Python", "repo": "lit-llama", "new_stars": 948, "stars": 2139, "owner": "Lightning-AI", "forks": 104},
{"description": "Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.", "language": "Python", "repo": "transformers", "new_stars": 2119, "stars": 91048, "owner": "huggingface", "forks": 19320},
{"description": "Build voice-based LLM agents. Modular + open source.", "language": "Python", "repo": "vocode-python", "new_stars": 387, "stars": 907, "owner": "vocodedev", "forks": 46},
{"description": "something like visual-chatgpt, \u6587\u5fc3\u4e00\u8a00\u7684\u5f00\u6e90\u7248", "language": "Python", "repo": "visual-openllm", "new_stars": 297, "stars": 695, "owner": "visual-openllm", "forks": 65},
{"description": null, "language": "Python", "repo": "ChatDoctor", "new_stars": 735, "stars": 2073, "owner": "Kent0n-Li", "forks": 214},
{"description": "\u3010\u7f16\u7a0b\u968f\u60f3\u3011\u6574\u7406\u7684\u300a\u592a\u5b50\u515a\u5173\u7cfb\u7f51\u7edc\u300b\uff0c\u4e13\u95e8\u63ed\u9732\u8d75\u56fd\u7684\u6743\u8d35", "language": "Python", "repo": "zhao", "new_stars": 381, "stars": 12312, "owner": "programthink", "forks": 2763},
{"description": "the open source embedding database", "language": "Python", "repo": "chroma", "new_stars": 341, "stars": 1370, "owner": "chroma-core", "forks": 74},
{"description": "PEFT: State-of-the-art Parameter-Efficient Fine-Tuning.", "language": "Python", "repo": "peft", "new_stars": 566, "stars": 3363, "owner": "huggingface", "forks": 215},
{"description": "Enjoy reading with your favorite style.", "language": "Python", "repo": "ebook-GPT-translator", "new_stars": 292, "stars": 765, "owner": "jesselau76", "forks": 82},
{"description": "Python - 100\u5929\u4ece\u65b0\u624b\u5230\u5927\u5e08", "language": "Python", "repo": "Python-100-Days", "new_stars": 483, "stars": 132655, "owner": "jackfrued", "forks": 48532},
{"description": "Stable Diffusion with Core ML on Apple Silicon", "language": "Python", "repo": "ml-stable-diffusion", "new_stars": 4251, "stars": 10533, "owner": "apple", "forks": 466},
{"description": "\u4e2d\u6587LLaMA&Alpaca\u5927\u8bed\u8a00\u6a21\u578b+\u672c\u5730\u90e8\u7f72 (Chinese LLaMA & Alpaca LLMs)", "language": "Python", "repo": "Chinese-LLaMA-Alpaca", "new_stars": 2205, "stars": 3208, "owner": "ymcui", "forks": 281},
{"description": "A batteries-included library for building AI-powered software", "language": "Python", "repo": "marvin", "new_stars": 898, "stars": 1427, "owner": "PrefectHQ", "forks": 53},
{"description": "\u514d\u8d39\u7684 ChatGPT \u955c\u50cf\u7f51\u7ad9\u5217\u8868\uff0c\u6301\u7eed\u66f4\u65b0\u3002List of free ChatGPT mirror sites, continuously updated.", "language": "Python", "repo": "awesome-free-chatgpt", "new_stars": 582, "stars": 903, "owner": "LiLittleCat", "forks": 61},
{"description": "A command-line productivity tool powered by ChatGPT, will help you accomplish your tasks faster and more efficiently.", "language": "Python", "repo": "shell_gpt", "new_stars": 467, "stars": 3917, "owner": "TheR1D", "forks": 237},
{"description": "A collective list of free APIs", "language": "Python", "repo": "public-apis", "new_stars": 2392, "stars": 234888, "owner": "public-apis", "forks": 26683},
{"description": "Learn how to design large-scale systems. Prep for the system design interview. Includes Anki flashcards.", "language": "Python", "repo": "system-design-primer", "new_stars": 1515, "stars": 216976, "owner": "donnemartin", "forks": 38572},
{"description": "CodeGeeX: An Open Multilingual Code Generation Model", "language": "Python", "repo": "CodeGeeX", "new_stars": 371, "stars": 3921, "owner": "THUDM", "forks": 257}
]