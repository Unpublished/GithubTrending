[
{"description": "gpt4all: an ecosystem of open-source chatbots trained on a massive collections of clean assistant data including code, stories and dialogue", "language": "Python", "repo": "gpt4all", "new_stars": 12941, "stars": 23934, "owner": "nomic-ai", "forks": 2420},
{"description": "\u79d1\u7814\u5de5\u4f5c\u4e13\u7528ChatGPT\u62d3\u5c55\uff0c\u7279\u522b\u4f18\u5316\u5b66\u672fPaper\u6da6\u8272\u4f53\u9a8c\uff0c\u652f\u6301\u81ea\u5b9a\u4e49\u5feb\u6377\u6309\u94ae\uff0c\u652f\u6301\u81ea\u5b9a\u4e49\u51fd\u6570\u63d2\u4ef6\uff0c\u652f\u6301markdown\u8868\u683c\u663e\u793a\uff0cTex\u516c\u5f0f\u53cc\u663e\u793a\uff0c\u4ee3\u7801\u663e\u793a\u529f\u80fd\u5b8c\u5584\uff0c\u65b0\u589e\u672c\u5730Python/C++/Go\u9879\u76ee\u6811\u5256\u6790\u529f\u80fd/\u9879\u76ee\u6e90\u4ee3\u7801\u81ea\u8bd1\u89e3\u80fd\u529b\uff0c\u65b0\u589ePDF\u548cWord\u6587\u732e\u6279\u91cf\u603b\u7ed3\u529f\u80fd/PDF\u8bba\u6587\u5168\u6587\u7ffb\u8bd1\u529f\u80fd", "language": "Python", "repo": "chatgpt_academic", "new_stars": 9476, "stars": 23233, "owner": "binary-husky", "forks": 2558},
{"description": "Making large AI models cheaper, faster and more accessible", "language": "Python", "repo": "ColossalAI", "new_stars": 4023, "stars": 27135, "owner": "hpcaitech", "forks": 3084},
{"description": null, "language": "Python", "repo": "ChatDoctor", "new_stars": 735, "stars": 2050, "owner": "Kent0n-Li", "forks": 213},
{"description": "An open-source framework for training large multimodal models", "language": "Python", "repo": "open_flamingo", "new_stars": 501, "stars": 1494, "owner": "mlfoundations", "forks": 86},
{"description": "Build and control your own LLMs", "language": "Python", "repo": "xturing", "new_stars": 776, "stars": 1207, "owner": "stochasticai", "forks": 80},
{"description": "\u3010\u7f16\u7a0b\u968f\u60f3\u3011\u6574\u7406\u7684\u300a\u592a\u5b50\u515a\u5173\u7cfb\u7f51\u7edc\u300b\uff0c\u4e13\u95e8\u63ed\u9732\u8d75\u56fd\u7684\u6743\u8d35", "language": "Python", "repo": "zhao", "new_stars": 381, "stars": 12312, "owner": "programthink", "forks": 2763},
{"description": "Implementation of the LLaMA language model based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed.", "language": "Python", "repo": "lit-llama", "new_stars": 948, "stars": 2126, "owner": "Lightning-AI", "forks": 104},
{"description": "something like visual-chatgpt, \u6587\u5fc3\u4e00\u8a00\u7684\u5f00\u6e90\u7248", "language": "Python", "repo": "visual-openllm", "new_stars": 297, "stars": 693, "owner": "visual-openllm", "forks": 65},
{"description": "PEFT: State-of-the-art Parameter-Efficient Fine-Tuning.", "language": "Python", "repo": "peft", "new_stars": 566, "stars": 3353, "owner": "huggingface", "forks": 213},
{"description": "Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.", "language": "Python", "repo": "transformers", "new_stars": 2119, "stars": 91022, "owner": "huggingface", "forks": 19318},
{"description": "Enjoy reading with your favorite style.", "language": "Python", "repo": "ebook-GPT-translator", "new_stars": 292, "stars": 763, "owner": "jesselau76", "forks": 82},
{"description": "Building applications with LLMs through composability", "language": "Python", "repo": "langchain", "new_stars": 3728, "stars": 22169, "owner": "hwchase17", "forks": 2040},
{"description": "A command-line productivity tool powered by ChatGPT, will help you accomplish your tasks faster and more efficiently.", "language": "Python", "repo": "shell_gpt", "new_stars": 467, "stars": 3915, "owner": "TheR1D", "forks": 237},
{"description": "CodeGeeX: An Open Multilingual Code Generation Model", "language": "Python", "repo": "CodeGeeX", "new_stars": 371, "stars": 3919, "owner": "THUDM", "forks": 257},
{"description": "Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation", "language": "Python", "repo": "Tune-A-Video", "new_stars": 494, "stars": 2793, "owner": "showlab", "forks": 212},
{"description": "A Telegram bot that integrates with OpenAI's official ChatGPT APIs to provide answers, written in Python", "language": "Python", "repo": "chatgpt-telegram-bot", "new_stars": 174, "stars": 942, "owner": "n3d1117", "forks": 261},
{"description": "A minimal PyTorch re-implementation of the OpenAI GPT (Generative Pretrained Transformer) training", "language": "Python", "repo": "minGPT", "new_stars": 351, "stars": 14213, "owner": "karpathy", "forks": 1644},
{"description": "LangFlow is a UI for LangChain, designed with react-flow to provide an effortless way to experiment and prototype flows.", "language": "Python", "repo": "langflow", "new_stars": 718, "stars": 3568, "owner": "logspace-ai", "forks": 259},
{"description": "Curso para aprender el lenguaje de programaci\u00f3n Python desde cero y para principiantes. M\u00e1s de 30 clases, 25 horas en v\u00eddeo, c\u00f3digo y grupo de chat. Desde sus fundamentos hasta la creaci\u00f3n de un API Backend con base de datos y m\u00e1s...", "language": "Python", "repo": "Hello-Python", "new_stars": 735, "stars": 10961, "owner": "mouredev", "forks": 758},
{"description": "Stable Diffusion with Core ML on Apple Silicon", "language": "Python", "repo": "ml-stable-diffusion", "new_stars": 4251, "stars": 10523, "owner": "apple", "forks": 465},
{"description": "\u4e2d\u6587LLaMA&Alpaca\u5927\u8bed\u8a00\u6a21\u578b+\u672c\u5730\u90e8\u7f72 (Chinese LLaMA & Alpaca LLMs)", "language": "Python", "repo": "Chinese-LLaMA-Alpaca", "new_stars": 2205, "stars": 3177, "owner": "ymcui", "forks": 278},
{"description": "Fine-tuning LLaMA to follow instructions within 1 Hour and 1.2M Parameters", "language": "Python", "repo": "LLaMA-Adapter", "new_stars": 1156, "stars": 1988, "owner": "ZrrSkywalker", "forks": 118},
{"description": "\u514d\u8d39\u7684 ChatGPT \u955c\u50cf\u7f51\u7ad9\u5217\u8868\uff0c\u6301\u7eed\u66f4\u65b0\u3002List of free ChatGPT mirror sites, continuously updated.", "language": "Python", "repo": "awesome-free-chatgpt", "new_stars": 582, "stars": 895, "owner": "LiLittleCat", "forks": 60},
{"description": "Alpaca dataset from Stanford, cleaned and curated", "language": "Python", "repo": "AlpacaDataCleaned", "new_stars": 156, "stars": 781, "owner": "gururise", "forks": 83}
]