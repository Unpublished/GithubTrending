[
{"description": "gpt4all: an ecosystem of open-source chatbots trained on a massive collections of clean assistant data including code, stories and dialogue", "language": "Python", "repo": "gpt4all", "new_stars": 15314, "stars": 23041, "owner": "nomic-ai", "forks": 2319},
{"description": "\u79d1\u7814\u5de5\u4f5c\u4e13\u7528ChatGPT\u62d3\u5c55\uff0c\u7279\u522b\u4f18\u5316\u5b66\u672fPaper\u6da6\u8272\u4f53\u9a8c\uff0c\u652f\u6301\u81ea\u5b9a\u4e49\u5feb\u6377\u6309\u94ae\uff0c\u652f\u6301\u81ea\u5b9a\u4e49\u51fd\u6570\u63d2\u4ef6\uff0c\u652f\u6301markdown\u8868\u683c\u663e\u793a\uff0cTex\u516c\u5f0f\u53cc\u663e\u793a\uff0c\u4ee3\u7801\u663e\u793a\u529f\u80fd\u5b8c\u5584\uff0c\u65b0\u589e\u672c\u5730Python/C++/Go\u9879\u76ee\u6811\u5256\u6790\u529f\u80fd/\u9879\u76ee\u6e90\u4ee3\u7801\u81ea\u8bd1\u89e3\u80fd\u529b\uff0c\u65b0\u589ePDF\u548cWord\u6587\u732e\u6279\u91cf\u603b\u7ed3\u529f\u80fd/PDF\u8bba\u6587\u5168\u6587\u7ffb\u8bd1\u529f\u80fd", "language": "Python", "repo": "chatgpt_academic", "new_stars": 12755, "stars": 22537, "owner": "binary-husky", "forks": 2477},
{"description": "Making large AI models cheaper, faster and more accessible", "language": "Python", "repo": "ColossalAI", "new_stars": 5776, "stars": 27003, "owner": "hpcaitech", "forks": 3067},
{"description": null, "language": "Python", "repo": "ChatDoctor", "new_stars": 1164, "stars": 1941, "owner": "Kent0n-Li", "forks": 199},
{"description": "An open-source framework for training large multimodal models", "language": "Python", "repo": "open_flamingo", "new_stars": 522, "stars": 1469, "owner": "mlfoundations", "forks": 83},
{"description": "Build and control your own LLMs", "language": "Python", "repo": "xturing", "new_stars": 714, "stars": 1162, "owner": "stochasticai", "forks": 78},
{"description": "\u3010\u7f16\u7a0b\u968f\u60f3\u3011\u6574\u7406\u7684\u300a\u592a\u5b50\u515a\u5173\u7cfb\u7f51\u7edc\u300b\uff0c\u4e13\u95e8\u63ed\u9732\u8d75\u56fd\u7684\u6743\u8d35", "language": "Python", "repo": "zhao", "new_stars": 410, "stars": 12302, "owner": "programthink", "forks": 2761},
{"description": "Implementation of the LLaMA language model based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed.", "language": "Python", "repo": "lit-llama", "new_stars": 1131, "stars": 2044, "owner": "Lightning-AI", "forks": 98},
{"description": "something like visual-chatgpt, \u6587\u5fc3\u4e00\u8a00\u7684\u5f00\u6e90\u7248", "language": "Python", "repo": "visual-openllm", "new_stars": 421, "stars": 672, "owner": "visual-openllm", "forks": 64},
{"description": "PEFT: State-of-the-art Parameter-Efficient Fine-Tuning.", "language": "Python", "repo": "peft", "new_stars": 617, "stars": 3288, "owner": "huggingface", "forks": 210},
{"description": "Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.", "language": "Python", "repo": "transformers", "new_stars": 2090, "stars": 90791, "owner": "huggingface", "forks": 19292},
{"description": "Enjoy reading with your favorite style.", "language": "Python", "repo": "ebook-GPT-translator", "new_stars": 380, "stars": 752, "owner": "jesselau76", "forks": 83},
{"description": "Building applications with LLMs through composability", "language": "Python", "repo": "langchain", "new_stars": 3706, "stars": 21746, "owner": "hwchase17", "forks": 1999},
{"description": "A command-line productivity tool powered by ChatGPT, will help you accomplish your tasks faster and more efficiently.", "language": "Python", "repo": "shell_gpt", "new_stars": 517, "stars": 3884, "owner": "TheR1D", "forks": 236},
{"description": "CodeGeeX: An Open Multilingual Code Generation Model", "language": "Python", "repo": "CodeGeeX", "new_stars": 343, "stars": 3894, "owner": "THUDM", "forks": 254},
{"description": "Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation", "language": "Python", "repo": "Tune-A-Video", "new_stars": 713, "stars": 2774, "owner": "showlab", "forks": 210},
{"description": "A Telegram bot that integrates with OpenAI's official ChatGPT APIs to provide answers, written in Python", "language": "Python", "repo": "chatgpt-telegram-bot", "new_stars": 193, "stars": 933, "owner": "n3d1117", "forks": 259},
{"description": "A minimal PyTorch re-implementation of the OpenAI GPT (Generative Pretrained Transformer) training", "language": "Python", "repo": "minGPT", "new_stars": 450, "stars": 14196, "owner": "karpathy", "forks": 1642},
{"description": "LangFlow is a UI for LangChain, designed with react-flow to provide an effortless way to experiment and prototype flows.", "language": "Python", "repo": "langflow", "new_stars": 1025, "stars": 3500, "owner": "logspace-ai", "forks": 255},
{"description": "Curso para aprender el lenguaje de programaci\u00f3n Python desde cero y para principiantes. M\u00e1s de 30 clases, 25 horas en v\u00eddeo, c\u00f3digo y grupo de chat. Desde sus fundamentos hasta la creaci\u00f3n de un API Backend con base de datos y m\u00e1s...", "language": "Python", "repo": "Hello-Python", "new_stars": 901, "stars": 10944, "owner": "mouredev", "forks": 756},
{"description": "Stable Diffusion with Core ML on Apple Silicon", "language": "Python", "repo": "ml-stable-diffusion", "new_stars": 4109, "stars": 10417, "owner": "apple", "forks": 459},
{"description": "\u4e2d\u6587LLaMA&Alpaca\u5927\u8bed\u8a00\u6a21\u578b+\u672c\u5730\u90e8\u7f72 (Chinese LLaMA & Alpaca LLMs)", "language": "Python", "repo": "Chinese-LLaMA-Alpaca", "new_stars": 2198, "stars": 3009, "owner": "ymcui", "forks": 249},
{"description": "Fine-tuning LLaMA to follow instructions within 1 Hour and 1.2M Parameters", "language": "Python", "repo": "LLaMA-Adapter", "new_stars": 1222, "stars": 1962, "owner": "ZrrSkywalker", "forks": 118},
{"description": "\u514d\u8d39\u7684 ChatGPT \u955c\u50cf\u7f51\u7ad9\u5217\u8868\uff0c\u6301\u7eed\u66f4\u65b0\u3002List of free ChatGPT mirror sites, continuously updated.", "language": "Python", "repo": "awesome-free-chatgpt", "new_stars": 535, "stars": 816, "owner": "LiLittleCat", "forks": 52},
{"description": "Alpaca dataset from Stanford, cleaned and curated", "language": "Python", "repo": "AlpacaDataCleaned", "new_stars": 174, "stars": 768, "owner": "gururise", "forks": 80}
]