[
{"description": "Inference code for LLaMA models", "language": "Python", "repo": "llama", "new_stars": 10660, "stars": 34719, "owner": "facebookresearch", "forks": 5463},
{"description": "ChatGLM2-6B: An Open Bilingual Chat LLM | \u5f00\u6e90\u53cc\u8bed\u5bf9\u8bdd\u8bed\u8a00\u6a21\u578b", "language": "Python", "repo": "ChatGLM2-6B", "new_stars": 9244, "stars": 10155, "owner": "THUDM", "forks": 1654},
{"description": "GPT 3.5/4 with a Chat Web UI. No API key required.", "language": "Python", "repo": "freegpt-webui", "new_stars": 3789, "stars": 4004, "owner": "ramonvc", "forks": 1181},
{"description": "Fast Segment Anything", "language": "Python", "repo": "FastSAM", "new_stars": 4114, "stars": 5040, "owner": "CASIA-IVA-Lab", "forks": 796},
{"description": "Private Q&A and summarization of documents+images or chat with local GPT, 100% private, Apache 2.0. Supports LLaMa2, llama.cpp, and more. Demo:", "language": "Python", "repo": "h2ogpt", "new_stars": 3029, "stars": 5958, "owner": "h2oai", "forks": 680},
{"description": "You like pytorch? You like micrograd? You love tinygrad!", "language": "Python", "repo": "tinygrad", "new_stars": 3306, "stars": 18333, "owner": "tinygrad", "forks": 2329},
{"description": "Large-scale Self-supervised Pre-training Across Tasks, Languages, and Modalities", "language": "Python", "repo": "unilm", "new_stars": 1792, "stars": 14617, "owner": "microsoft", "forks": 2037},
{"description": null, "language": "Python", "repo": "chatgpt-retrieval", "new_stars": 469, "stars": 974, "owner": "techleadhd", "forks": 452},
{"description": "A powerful and modular stable diffusion GUI with a graph/nodes interface.", "language": "Python", "repo": "ComfyUI", "new_stars": 1896, "stars": 8163, "owner": "comfyanonymous", "forks": 732},
{"description": "Fast and memory-efficient exact attention", "language": "Python", "repo": "flash-attention", "new_stars": 1809, "stars": 5581, "owner": "Dao-AILab", "forks": 439},
{"description": "Fine-tuning ChatGLM-6B with PEFT | \u57fa\u4e8e PEFT \u7684\u9ad8\u6548 ChatGLM \u5fae\u8c03", "language": "Python", "repo": "ChatGLM-Efficient-Tuning", "new_stars": 1145, "stars": 2513, "owner": "hiyouga", "forks": 358},
{"description": "Generative Models by Stability AI", "language": "Python", "repo": "generative-models", "new_stars": 1791, "stars": 3216, "owner": "Stability-AI", "forks": 589},
{"description": "A high-throughput and memory-efficient inference and serving engine for LLMs", "language": "Python", "repo": "vllm", "new_stars": 1885, "stars": 4099, "owner": "vllm-project", "forks": 389},
{"description": "Voice data <= 10 mins can also be used to train a good VC model!", "language": "Python", "repo": "Retrieval-based-Voice-Conversion-WebUI", "new_stars": 2852, "stars": 8370, "owner": "RVC-Project", "forks": 1229},
{"description": "[PREVIEW] Sample code for a simple web chat experience targeting chatGPT through AOAI.", "language": "Python", "repo": "sample-app-aoai-chatGPT", "new_stars": 108, "stars": 292, "owner": "microsoft", "forks": 275},
{"description": "\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u30dc\u30a4\u30b9\u30c1\u30a7\u30f3\u30b8\u30e3\u30fc Realtime Voice Changer", "language": "Python", "repo": "voice-changer", "new_stars": 3283, "stars": 8502, "owner": "w-okada", "forks": 958},
{"description": "roop extension for StableDiffusion web-ui", "language": "Python", "repo": "sd-webui-roop", "new_stars": 1003, "stars": 1740, "owner": "s0md3v", "forks": 360},
{"description": "WebGLM: An Efficient Web-enhanced Question Answering System (KDD 2023)", "language": "Python", "repo": "WebGLM", "new_stars": 531, "stars": 1187, "owner": "THUDM", "forks": 115},
{"description": "Faster Whisper transcription with CTranslate2", "language": "Python", "repo": "faster-whisper", "new_stars": 1058, "stars": 3755, "owner": "guillaumekln", "forks": 266},
{"description": "Unified AI", "language": "Python", "repo": "ivy", "new_stars": 799, "stars": 12240, "owner": "unifyai", "forks": 4830},
{"description": "Official Code for DragGAN (SIGGRAPH 2023)", "language": "Python", "repo": "DragGAN", "new_stars": 14813, "stars": 31400, "owner": "XingangPan", "forks": 3455},
{"description": "A more memory-efficient rewrite of the HF transformers implementation of Llama for use with quantized weights.", "language": "Python", "repo": "exllama", "new_stars": 823, "stars": 1351, "owner": "turboderp", "forks": 164},
{"description": "aider is GPT powered coding in your terminal", "language": "Python", "repo": "aider", "new_stars": 2109, "stars": 2607, "owner": "paul-gauthier", "forks": 435},
{"description": "Hey there new grad", "language": "Python", "repo": "New-Grad-2024", "new_stars": 1152, "stars": 2240, "owner": "ReaVNaiL", "forks": 129},
{"description": "Framework to easily create LLM powered bots over any dataset.", "language": "Python", "repo": "embedchain", "new_stars": 2815, "stars": 3727, "owner": "embedchain", "forks": 773}
]