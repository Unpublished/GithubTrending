[
{"description": "Specify what you want it to build, the AI asks for clarification, and then builds it.", "language": "Python", "repo": "gpt-engineer", "new_stars": 23230, "stars": 29781, "owner": "AntonOsika", "forks": 4705},
{"description": "An open platform for operating large language models (LLMs) in production. Fine-tune, serve, deploy, and monitor any LLMs with ease.", "language": "Python", "repo": "OpenLLM", "new_stars": 2803, "stars": 3670, "owner": "bentoml", "forks": 212},
{"description": "Official codebase for I-JEPA, the Image-based Joint-Embedding Predictive Architecture. First outlined in the CVPR paper, \"Self-supervised learning from images with a joint-embedding predictive architecture.\"", "language": "Python", "repo": "ijepa", "new_stars": 1120, "stars": 1821, "owner": "facebookresearch", "forks": 317},
{"description": "Family of instruction-following LLMs powered by Evol-Instruct: WizardLM, WizardCoder", "language": "Python", "repo": "WizardLM", "new_stars": 845, "stars": 3178, "owner": "nlpxucan", "forks": 233},
{"description": "H2O LLM Studio - a framework and no-code GUI for fine-tuning LLMs", "language": "Python", "repo": "h2o-llmstudio", "new_stars": 121, "stars": 1797, "owner": "h2oai", "forks": 162},
{"description": "An Extensible Toolkit for Finetuning and Inference of Large Foundation Models. Large Model for All.", "language": "Python", "repo": "LMFlow", "new_stars": 350, "stars": 6101, "owner": "OptimalScale", "forks": 935},
{"description": "A Langchain app that allows you to chat with multiple PDFs", "language": "Python", "repo": "ask-multiple-pdfs", "new_stars": 167, "stars": 350, "owner": "alejandro-ao", "forks": 145},
{"description": "Implementation of Falcon, StableLM, Pythia, INCITE language models based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed.", "language": "Python", "repo": "lit-gpt", "new_stars": 251, "stars": 1291, "owner": "Lightning-AI", "forks": 102},
{"description": "Unified AI", "language": "Python", "repo": "ivy", "new_stars": 147, "stars": 11325, "owner": "unifyai", "forks": 4365},
{"description": "Fine-tuning LLaMA with PEFT (PT+SFT+RLHF with QLoRA)", "language": "Python", "repo": "LLaMA-Efficient-Tuning", "new_stars": 635, "stars": 845, "owner": "hiyouga", "forks": 445},
{"description": "Stable Diffusion with Core ML on Apple Silicon", "language": "Python", "repo": "ml-stable-diffusion", "new_stars": 752, "stars": 13237, "owner": "apple", "forks": 654},
{"description": "Official implementation of our ArXiv paper \"Augmenting Language Models with Long-Term Memory\".", "language": "Python", "repo": "LongMem", "new_stars": 323, "stars": 519, "owner": "Victorwz", "forks": 98},
{"description": "OpenMMLab Multimodal Advanced, Generative, and Intelligent Creation Toolbox. Unlock the magic", "language": "Python", "repo": "mmagic", "new_stars": 395, "stars": 5273, "owner": "open-mmlab", "forks": 890},
{"description": "Join us at H2O.ai to make the world's best open-source GPT with document and image Q&A, 100% private chat, no data leaks, Apache 2.0", "language": "Python", "repo": "h2ogpt", "new_stars": 640, "stars": 2833, "owner": "h2oai", "forks": 246},
{"description": "Macaw-LLM: Multi-Modal Language Modeling with Image, Video, Audio, and Text Integration", "language": "Python", "repo": "Macaw-LLM", "new_stars": 355, "stars": 972, "owner": "lyuchenyang", "forks": 66},
{"description": "Building applications with LLMs through composability", "language": "Python", "repo": "langchain", "new_stars": 2066, "stars": 49707, "owner": "hwchase17", "forks": 6155},
{"description": "Python package for easily interfacing with chat apps, with robust features and minimal code complexity.", "language": "Python", "repo": "simpleaichat", "new_stars": 418, "stars": 976, "owner": "minimaxir", "forks": 37},
{"description": "One place for all the default credentials to assist the Blue/Red teamers activities on finding devices with default password", "language": "Python", "repo": "DefaultCreds-cheat-sheet", "new_stars": 330, "stars": 4391, "owner": "ihebski", "forks": 589},
{"description": "langchain-ChatGLM, local knowledge based ChatGLM with langchain \uff5c \u57fa\u4e8e\u672c\u5730\u77e5\u8bc6\u5e93\u7684 ChatGLM \u95ee\u7b54", "language": "Python", "repo": "langchain-ChatGLM", "new_stars": 791, "stars": 9884, "owner": "imClumsyPanda", "forks": 1436},
{"description": "DeepSpeed is a deep learning optimization library that makes distributed training and inference easy, efficient, and effective.", "language": "Python", "repo": "DeepSpeed", "new_stars": 467, "stars": 26267, "owner": "microsoft", "forks": 3159},
{"description": "A curated list of awesome Python frameworks, libraries, software and resources", "language": "Python", "repo": "awesome-python", "new_stars": 785, "stars": 171815, "owner": "vinta", "forks": 23383},
{"description": "Ready-to-use OCR with 80+ supported languages and all popular writing scripts including Latin, Chinese, Arabic, Devanagari, Cyrillic and etc.", "language": "Python", "repo": "EasyOCR", "new_stars": 225, "stars": 18558, "owner": "JaidedAI", "forks": 2625},
{"description": "Audiocraft is a library for audio processing and generation with deep learning. It features the state-of-the-art EnCodec audio compressor / tokenizer, along with MusicGen, a simple and controllable music generation LM with textual and melodic conditioning.", "language": "Python", "repo": "audiocraft", "new_stars": 1539, "stars": 7723, "owner": "facebookresearch", "forks": 670},
{"description": "Streamlit \u2014 A faster way to build and share data apps.", "language": "Python", "repo": "streamlit", "new_stars": 202, "stars": 25503, "owner": "streamlit", "forks": 2254},
{"description": "StableSR for Stable Diffusion WebUI - Ultra High-quality Image Upscaler", "language": "Python", "repo": "sd-webui-stablesr", "new_stars": 159, "stars": 469, "owner": "pkuliyi2015", "forks": 22}
]