[
{"description": "<", "language": "Python", "repo": "SuperAGI", "new_stars": 8197, "stars": 9739, "owner": "TransformerOptimus", "forks": 1049},
{"description": "one-click deepfake (face swap)", "language": "Python", "repo": "roop", "new_stars": 6855, "stars": 14820, "owner": "s0md3v", "forks": 2644},
{"description": "Hackable implementation of state-of-the-art open-source LLMs based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed.", "language": "Python", "repo": "lit-gpt", "new_stars": 1249, "stars": 1539, "owner": "Lightning-AI", "forks": 141},
{"description": "You like pytorch? You like micrograd? You love tinygrad!", "language": "Python", "repo": "tinygrad", "new_stars": 2547, "stars": 16914, "owner": "geohot", "forks": 1997},
{"description": "Fine-tuning ChatGLM-6B with PEFT | \u57fa\u4e8e PEFT \u7684\u9ad8\u6548 ChatGLM \u5fae\u8c03", "language": "Python", "repo": "ChatGLM-Efficient-Tuning", "new_stars": 785, "stars": 1892, "owner": "hiyouga", "forks": 273},
{"description": "Large Language Model Text Generation Inference", "language": "Python", "repo": "text-generation-inference", "new_stars": 1040, "stars": 2643, "owner": "huggingface", "forks": 237},
{"description": "Book_4_\u300a\u77e9\u9635\u529b\u91cf\u300b | \u9e22\u5c3e\u82b1\u4e66\uff1a\u4ece\u52a0\u51cf\u4e58\u9664\u5230\u673a\u5668\u5b66\u4e60\uff1b\u4e0a\u67b6\uff01", "language": "Python", "repo": "Book4_Power-of-Matrix", "new_stars": 1167, "stars": 4024, "owner": "Visualize-ML", "forks": 561},
{"description": "Join us at H2O.ai to make the world's best open-source GPT with document and image Q&A, 100% private chat, no data leaks, Apache 2.0", "language": "Python", "repo": "h2ogpt", "new_stars": 1411, "stars": 3323, "owner": "h2oai", "forks": 306},
{"description": "Family of instruction-following LLMs powered by Evol-Instruct: WizardLM, WizardCoder", "language": "Python", "repo": "WizardLM", "new_stars": 1745, "stars": 3647, "owner": "nlpxucan", "forks": 269},
{"description": "Unified AI", "language": "Python", "repo": "ivy", "new_stars": 820, "stars": 11741, "owner": "unifyai", "forks": 4557},
{"description": "Voice data <= 10 mins can also be used to train a good VC model!", "language": "Python", "repo": "Retrieval-based-Voice-Conversion-WebUI", "new_stars": 2464, "stars": 6366, "owner": "RVC-Project", "forks": 911},
{"description": "Train neural networks up to 7x faster", "language": "Python", "repo": "composer", "new_stars": 686, "stars": 4205, "owner": "mosaicml", "forks": 304},
{"description": "langchain-ChatGLM, local knowledge based ChatGLM with langchain \uff5c \u57fa\u4e8e\u672c\u5730\u77e5\u8bc6\u5e93\u7684 ChatGLM \u95ee\u7b54", "language": "Python", "repo": "langchain-ChatGLM", "new_stars": 3026, "stars": 10964, "owner": "imClumsyPanda", "forks": 1687},
{"description": "FastAPI framework, high performance, easy to learn, fast to code, ready for production", "language": "Python", "repo": "fastapi", "new_stars": 1300, "stars": 59887, "owner": "tiangolo", "forks": 5005},
{"description": "An easy-to-use LLMs quantization package with user-friendly apis, based on GPTQ algorithm.", "language": "Python", "repo": "AutoGPTQ", "new_stars": 509, "stars": 1031, "owner": "PanQiWei", "forks": 107},
{"description": "\ud83d\ude80 A simple way to train and use PyTorch models with multi-GPU, TPU, mixed-precision", "language": "Python", "repo": "accelerate", "new_stars": 398, "stars": 5124, "owner": "huggingface", "forks": 544},
{"description": "Official Code for DragGAN (SIGGRAPH 2023)", "language": "Python", "repo": "DragGAN", "new_stars": 14507, "stars": 29511, "owner": "XingangPan", "forks": 3168},
{"description": "FlagAI (Fast LArge-scale General AI models) is a fast, easy-to-use and extensible toolkit for large-scale model.", "language": "Python", "repo": "FlagAI", "new_stars": 2039, "stars": 3307, "owner": "FlagAI-Open", "forks": 470},
{"description": "WhisperX: Automatic Speech Recognition with Word-level Timestamps (& Diarization)", "language": "Python", "repo": "whisperX", "new_stars": 612, "stars": 3674, "owner": "m-bain", "forks": 312},
{"description": "[SIGGRAPH Asia 2022] VideoReTalking: Audio-based Lip Synchronization for Talking Head Video Editing In the Wild", "language": "Python", "repo": "video-retalking", "new_stars": 297, "stars": 963, "owner": "OpenTalker", "forks": 172},
{"description": "A list of useful payloads and bypass for Web Application Security and Pentest/CTF", "language": "Python", "repo": "PayloadsAllTheThings", "new_stars": 812, "stars": 48905, "owner": "swisskyrepo", "forks": 12826},
{"description": "Synapse: Matrix homeserver written in Python/Twisted.", "language": "Python", "repo": "synapse", "new_stars": 139, "stars": 11030, "owner": "matrix-org", "forks": 2056},
{"description": "Ray is a unified framework for scaling AI and Python applications. Ray consists of a core distributed runtime and a toolkit of libraries (Ray AIR) for accelerating ML workloads.", "language": "Python", "repo": "ray", "new_stars": 592, "stars": 26435, "owner": "ray-project", "forks": 4934},
{"description": "Chat with your documents on your local device using GPT models. No data leaves your device and 100% private.", "language": "Python", "repo": "localGPT", "new_stars": 5717, "stars": 9581, "owner": "PromtEngineer", "forks": 914},
{"description": "An Extensible Toolkit for Finetuning and Inference of Large Foundation Models. Large Models for All.", "language": "Python", "repo": "LMFlow", "new_stars": 1343, "stars": 6774, "owner": "OptimalScale", "forks": 988}
]