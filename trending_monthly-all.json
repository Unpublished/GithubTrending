[
{"description": "RAGFlow is an open-source RAG (Retrieval-Augmented Generation) engine based on deep document understanding.", "language": "Python", "repo": "ragflow", "new_stars": 5316, "stars": 6280, "owner": "infiniflow", "forks": 529},
{"description": "SWE-agent takes a GitHub issue and tries to automatically fix it, using GPT-4, or your LM of choice. It solves 12.29% of bugs in the SWE-bench evaluation set and takes just 1.5 minutes to run.", "language": "Python", "repo": "SWE-agent", "new_stars": 10061, "stars": 10113, "owner": "princeton-nlp", "forks": 977},
{"description": "A complete computer science study plan to become a software engineer.", "language": null, "repo": "coding-interview-university", "new_stars": 10770, "stars": 290897, "owner": "jwasham", "forks": 73710},
{"description": "Vue3 + Pinia + Vite5 \u4eff\u6296\u97f3\uff0cVue \u5728\u79fb\u52a8\u7aef\u7684\u6700\u4f73\u5b9e\u8df5 . Imitate TikTok \uff0cVue Best practices on Mobile", "language": "Vue", "repo": "douyin", "new_stars": 5485, "stars": 6473, "owner": "zyronon", "forks": 1609},
{"description": "Instant voice cloning by MyShell.", "language": "Python", "repo": "OpenVoice", "new_stars": 6928, "stars": 23431, "owner": "myshell-ai", "forks": 2146},
{"description": "Dify is an open-source LLM app development platform. Dify's intuitive interface combines AI workflow, RAG pipeline, agent capabilities, model management, observability features and more, letting you quickly go from prototype to production.", "language": "TypeScript", "repo": "dify", "new_stars": 7330, "stars": 26061, "owner": "langgenius", "forks": 3433},
{"description": "OpenUI let's you describe UI using your imagination, then see it rendered live.", "language": "TypeScript", "repo": "openui", "new_stars": 4712, "stars": 6408, "owner": "wandb", "forks": 576},
{"description": "Llama\u4e2d\u6587\u793e\u533a\uff0cLlama3\u5728\u7ebf\u4f53\u9a8c\u548c\u5fae\u8c03\u6a21\u578b\u5df2\u5f00\u653e\uff0c\u5b9e\u65f6\u6c47\u603b\u6700\u65b0Llama3\u5b66\u4e60\u8d44\u6599\uff0c\u5df2\u5c06\u6240\u6709\u4ee3\u7801\u66f4\u65b0\u9002\u914dLlama3\uff0c\u6784\u5efa\u6700\u597d\u7684\u4e2d\u6587Llama\u5927\u6a21\u578b\uff0c\u5b8c\u5168\u5f00\u6e90\u53ef\u5546\u7528", "language": "Python", "repo": "Llama-Chinese", "new_stars": 2400, "stars": 11418, "owner": "LlamaFamily", "forks": 1069},
{"description": "\u8ba1\u7b97\u673a\u81ea\u5b66\u6307\u5357", "language": "HTML", "repo": "cs-self-learning", "new_stars": 6770, "stars": 50069, "owner": "PKUFlyingPig", "forks": 6222},
{"description": "Utilize the unlimited free GPT-3.5-Turbo API service provided by the login-free ChatGPT Web.", "language": "JavaScript", "repo": "FreeGPT35", "new_stars": 2972, "stars": 2981, "owner": "missuo", "forks": 905},
{"description": "Unify Efficient Fine-Tuning of 100+ LLMs", "language": "Python", "repo": "LLaMA-Factory", "new_stars": 5478, "stars": 20796, "owner": "hiyouga", "forks": 2493},
{"description": "\ud83d\udc41\u200d\ud83d\udde8 Rare and exotic sats", "language": "Rust", "repo": "ord", "new_stars": 494, "stars": 3650, "owner": "ordinals", "forks": 1241},
{"description": "\u26d3\ufe0f Langflow is a dynamic graph where each node is an executable unit. Its modular and interactive design fosters rapid experimentation and prototyping, pushing hard on the limits of creativity.", "language": "JavaScript", "repo": "langflow", "new_stars": 2228, "stars": 17532, "owner": "langflow-ai", "forks": 2607},
{"description": "Get up and running with Llama 3, Mistral, Gemma, and other large language models.", "language": "Go", "repo": "ollama", "new_stars": 11056, "stars": 63185, "owner": "ollama", "forks": 4529},
{"description": "\ud83d\ude80 KIMI AI \u957f\u6587\u672c\u5927\u6a21\u578b\u9006\u5411API\u767d\u5ad6\u6d4b\u8bd5\u3010\u7279\u957f\uff1a\u957f\u6587\u672c\u89e3\u8bfb\u6574\u7406\u3011\uff0c\u652f\u6301\u9ad8\u901f\u6d41\u5f0f\u8f93\u51fa\u3001\u667a\u80fd\u4f53\u5bf9\u8bdd\u3001\u8054\u7f51\u641c\u7d22\u3001\u957f\u6587\u6863\u89e3\u8bfb\u3001\u56fe\u50cf\u89e3\u6790\u3001\u591a\u8f6e\u5bf9\u8bdd\uff0c\u96f6\u914d\u7f6e\u90e8\u7f72\uff0c\u591a\u8deftoken\u652f\u6301\uff0c\u81ea\u52a8\u6e05\u7406\u4f1a\u8bdd\u75d5\u8ff9\u3002", "language": "TypeScript", "repo": "kimi-free-api", "new_stars": 1548, "stars": 2501, "owner": "LLM-Red-Team", "forks": 355},
{"description": "30 days of Python programming challenge is a step-by-step guide to learn the Python programming language in 30 days. This challenge may take more than100 days, follow your own pace. These videos may help too:", "language": "Python", "repo": "30-Days-Of-Python", "new_stars": 1914, "stars": 31862, "owner": "Asabeneh", "forks": 6491},
{"description": "An open-source & self-hostable Heroku / Netlify / Vercel alternative.", "language": "PHP", "repo": "coolify", "new_stars": 2717, "stars": 14895, "owner": "coollabsio", "forks": 807},
{"description": "Question and Answer based on Anything.", "language": "Python", "repo": "QAnything", "new_stars": 2950, "stars": 8960, "owner": "netease-youdao", "forks": 841},
{"description": "Distribute and run LLMs with a single file.", "language": "C++", "repo": "llamafile", "new_stars": 3461, "stars": 14937, "owner": "Mozilla-Ocho", "forks": 736},
{"description": "Finetune Llama 3, Mistral & Gemma LLMs 2-5x faster with 80% less memory", "language": "Python", "repo": "unsloth", "new_stars": 3041, "stars": 8314, "owner": "unslothai", "forks": 522},
{"description": "Inference Llama 2 in one file of pure C", "language": "C", "repo": "llama2.c", "new_stars": 1279, "stars": 16015, "owner": "karpathy", "forks": 1824},
{"description": "aider is AI pair programming in your terminal", "language": "Python", "repo": "aider", "new_stars": 2589, "stars": 9711, "owner": "paul-gauthier", "forks": 967},
{"description": "A new project to resume development on the formerly open-source Redis project. We're calling it Valkey, since it's a twist on the key-value datastore.", "language": "C", "repo": "valkey", "new_stars": 7196, "stars": 13255, "owner": "valkey-io", "forks": 457},
{"description": "A Native-PyTorch Library for LLM Fine-tuning", "language": "Python", "repo": "torchtune", "new_stars": 2252, "stars": 2972, "owner": "pytorch", "forks": 197},
{"description": "Scripts for fine-tuning Meta Llama3 with composable FSDP & PEFT methods to cover single/multi-node GPUs. Supports default & custom datasets for applications such as summarization and Q&A. Supporting a number of candid inference solutions such as HF TGI, VLLM for local or cloud deployment. Demo apps to showcase Meta Llama3 for WhatsApp & Messenger.", "language": "Jupyter Notebook", "repo": "llama-recipes", "new_stars": 1277, "stars": 9366, "owner": "meta-llama", "forks": 1311}
]