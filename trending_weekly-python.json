[
{"description": "\u79d1\u7814\u5de5\u4f5c\u4e13\u7528ChatGPT\u62d3\u5c55\uff0c\u7279\u522b\u4f18\u5316\u5b66\u672fPaper\u6da6\u8272\u4f53\u9a8c\uff0c\u652f\u6301\u81ea\u5b9a\u4e49\u5feb\u6377\u6309\u94ae\uff0c\u652f\u6301\u81ea\u5b9a\u4e49\u51fd\u6570\u63d2\u4ef6\uff0c\u652f\u6301markdown\u8868\u683c\u663e\u793a\uff0cTex\u516c\u5f0f\u53cc\u663e\u793a\uff0c\u4ee3\u7801\u663e\u793a\u529f\u80fd\u5b8c\u5584\uff0c\u65b0\u589e\u672c\u5730Python/C++/Go\u9879\u76ee\u6811\u5256\u6790\u529f\u80fd/\u9879\u76ee\u6e90\u4ee3\u7801\u81ea\u8bd1\u89e3\u80fd\u529b\uff0c\u65b0\u589ePDF\u548cWord\u6587\u732e\u6279\u91cf\u603b\u7ed3\u529f\u80fd", "language": "Python", "repo": "chatgpt_academic", "new_stars": 15506, "stars": 21790, "owner": "binary-husky", "forks": 2391},
{"description": "Making large AI models cheaper, faster and more accessible", "language": "Python", "repo": "ColossalAI", "new_stars": 7140, "stars": 26782, "owner": "hpcaitech", "forks": 3030},
{"description": null, "language": "Python", "repo": "ChatDoctor", "new_stars": 1209, "stars": 1852, "owner": "Kent0n-Li", "forks": 186},
{"description": "PEFT: State-of-the-art Parameter-Efficient Fine-Tuning.", "language": "Python", "repo": "peft", "new_stars": 775, "stars": 3183, "owner": "huggingface", "forks": 206},
{"description": "\u3010\u7f16\u7a0b\u968f\u60f3\u3011\u6574\u7406\u7684\u300a\u592a\u5b50\u515a\u5173\u7cfb\u7f51\u7edc\u300b\uff0c\u4e13\u95e8\u63ed\u9732\u8d75\u56fd\u7684\u6743\u8d35", "language": "Python", "repo": "zhao", "new_stars": 404, "stars": 12290, "owner": "programthink", "forks": 2760},
{"description": "Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation", "language": "Python", "repo": "Tune-A-Video", "new_stars": 1143, "stars": 2742, "owner": "showlab", "forks": 208},
{"description": "Building applications with LLMs through composability", "language": "Python", "repo": "langchain", "new_stars": 3690, "stars": 21154, "owner": "hwchase17", "forks": 1935},
{"description": "Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.", "language": "Python", "repo": "transformers", "new_stars": 2008, "stars": 90484, "owner": "huggingface", "forks": 19262},
{"description": "Build and control your own LLMs", "language": "Python", "repo": "xturing", "new_stars": 709, "stars": 1087, "owner": "stochasticai", "forks": 72},
{"description": "Enjoy reading with your favorite style.", "language": "Python", "repo": "ebook-GPT-translator", "new_stars": 409, "stars": 734, "owner": "jesselau76", "forks": 82},
{"description": "Databricks\u2019 Dolly, a large language model trained on the Databricks Machine Learning Platform", "language": "Python", "repo": "dolly", "new_stars": 1399, "stars": 4175, "owner": "databrickslabs", "forks": 417},
{"description": "Use commands in English to control Blender with OpenAI's GPT-4", "language": "Python", "repo": "BlenderGPT", "new_stars": 823, "stars": 3077, "owner": "gd3kr", "forks": 184},
{"description": "A Telegram bot that integrates with OpenAI's official ChatGPT APIs to provide answers, written in Python", "language": "Python", "repo": "chatgpt-telegram-bot", "new_stars": 211, "stars": 917, "owner": "n3d1117", "forks": 255},
{"description": "Alpaca dataset from Stanford, cleaned and curated", "language": "Python", "repo": "AlpacaDataCleaned", "new_stars": 204, "stars": 750, "owner": "gururise", "forks": 79},
{"description": "A minimal PyTorch re-implementation of the OpenAI GPT (Generative Pretrained Transformer) training", "language": "Python", "repo": "minGPT", "new_stars": 445, "stars": 14157, "owner": "karpathy", "forks": 1638},
{"description": "A command-line productivity tool powered by ChatGPT, will help you accomplish your tasks faster and more efficiently.", "language": "Python", "repo": "shell_gpt", "new_stars": 573, "stars": 3840, "owner": "TheR1D", "forks": 231},
{"description": "The simplest, fastest repository for training/finetuning medium-sized GPTs.", "language": "Python", "repo": "nanoGPT", "new_stars": 625, "stars": 16978, "owner": "karpathy", "forks": 1873},
{"description": "gpt4all: an ecosystem of open-source chatbots trained on a massive collections of clean assistant data including code, stories and dialogue", "language": "Python", "repo": "gpt4all", "new_stars": 16397, "stars": 21391, "owner": "nomic-ai", "forks": 2138},
{"description": "Stable Diffusion with Core ML on Apple Silicon", "language": "Python", "repo": "ml-stable-diffusion", "new_stars": 3861, "stars": 10246, "owner": "apple", "forks": 451},
{"description": "Implementation of the LLaMA language model based on nanoGPT. Supports flash attention, quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed.", "language": "Python", "repo": "lit-llama", "new_stars": 1186, "stars": 2002, "owner": "Lightning-AI", "forks": 95},
{"description": "\u514d\u8d39\u7684 ChatGPT \u955c\u50cf\u7f51\u7ad9\u5217\u8868\uff0c\u6301\u7eed\u66f4\u65b0\u3002List of free ChatGPT mirror sites, continuously updated.", "language": "Python", "repo": "awesome-free-chatgpt", "new_stars": 530, "stars": 719, "owner": "LiLittleCat", "forks": 48},
{"description": "GLM-130B: An Open Bilingual Pre-Trained Model (ICLR 2023)", "language": "Python", "repo": "GLM-130B", "new_stars": 445, "stars": 3560, "owner": "THUDM", "forks": 233},
{"description": "Curso para aprender el lenguaje de programaci\u00f3n Python desde cero y para principiantes. M\u00e1s de 30 clases, 25 horas en v\u00eddeo, c\u00f3digo y grupo de chat. Desde sus fundamentos hasta la creaci\u00f3n de un API Backend con base de datos y m\u00e1s...", "language": "Python", "repo": "Hello-Python", "new_stars": 940, "stars": 10912, "owner": "mouredev", "forks": 756},
{"description": "something like visual-chatgpt, \u6587\u5fc3\u4e00\u8a00\u7684\u5f00\u6e90\u7248", "language": "Python", "repo": "visual-openllm", "new_stars": 441, "stars": 648, "owner": "visual-openllm", "forks": 62},
{"description": "CodeGeeX: An Open Multilingual Code Generation Model", "language": "Python", "repo": "CodeGeeX", "new_stars": 354, "stars": 3837, "owner": "THUDM", "forks": 251}
]