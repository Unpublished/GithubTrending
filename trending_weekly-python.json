[
{"description": "Specify what you want it to build, the AI asks for clarification, and then builds it.", "language": "Python", "repo": "gpt-engineer", "new_stars": 7623, "stars": 34122, "owner": "AntonOsika", "forks": 5664},
{"description": "Infinite Photorealistic Worlds using Procedural Generation", "language": "Python", "repo": "infinigen", "new_stars": 967, "stars": 3605, "owner": "princeton-vl", "forks": 364},
{"description": "Official Code for DragGAN (SIGGRAPH 2023)", "language": "Python", "repo": "DragGAN", "new_stars": 8721, "stars": 26319, "owner": "XingangPan", "forks": 2488},
{"description": "Open platform for operating LLMs in production", "language": "Python", "repo": "OpenLLM", "new_stars": 1102, "stars": 4557, "owner": "bentoml", "forks": 285},
{"description": "Unified AI", "language": "Python", "repo": "ivy", "new_stars": 322, "stars": 11612, "owner": "unifyai", "forks": 4483},
{"description": "WebGLM: An Efficient Web-enhanced Question Answering System (KDD 2023)", "language": "Python", "repo": "WebGLM", "new_stars": 383, "stars": 822, "owner": "THUDM", "forks": 78},
{"description": "A more memory-efficient rewrite of the HF transformers implementation of Llama for use with quantized weights.", "language": "Python", "repo": "exllama", "new_stars": 241, "stars": 785, "owner": "turboderp", "forks": 76},
{"description": "An Extensible Toolkit for Finetuning and Inference of Large Foundation Models. Large Model for All.", "language": "Python", "repo": "LMFlow", "new_stars": 566, "stars": 6615, "owner": "OptimalScale", "forks": 975},
{"description": "roop extension for StableDiffusion web-ui", "language": "Python", "repo": "sd-webui-roop", "new_stars": 719, "stars": 1003, "owner": "s0md3v", "forks": 230},
{"description": "Official PyTorch implementation of StyleGAN3", "language": "Python", "repo": "stylegan3", "new_stars": 258, "stars": 5517, "owner": "NVlabs", "forks": 973},
{"description": "Family of instruction-following LLMs powered by Evol-Instruct: WizardLM, WizardCoder", "language": "Python", "repo": "WizardLM", "new_stars": 440, "stars": 3512, "owner": "nlpxucan", "forks": 255},
{"description": "scikit-learn: machine learning in Python", "language": "Python", "repo": "scikit-learn", "new_stars": 269, "stars": 54915, "owner": "scikit-learn", "forks": 24406},
{"description": "High-Resolution Image Synthesis with Latent Diffusion Models", "language": "Python", "repo": "stablediffusion", "new_stars": 789, "stars": 25876, "owner": "Stability-AI", "forks": 3293},
{"description": "Label, clean and enrich text datasets with LLMs. Discord:", "language": "Python", "repo": "autolabel", "new_stars": 377, "stars": 941, "owner": "refuel-ai", "forks": 52},
{"description": "H2O LLM Studio - a framework and no-code GUI for fine-tuning LLMs", "language": "Python", "repo": "h2o-llmstudio", "new_stars": 178, "stars": 1964, "owner": "h2oai", "forks": 177},
{"description": "LLM training code for MosaicML foundation models", "language": "Python", "repo": "llm-foundry", "new_stars": 211, "stars": 2443, "owner": "mosaicml", "forks": 231},
{"description": "NVR with realtime local object detection for IP cameras", "language": "Python", "repo": "frigate", "new_stars": 101, "stars": 8530, "owner": "blakeblackshear", "forks": 862},
{"description": "Train neural networks up to 7x faster", "language": "Python", "repo": "composer", "new_stars": 121, "stars": 3798, "owner": "mosaicml", "forks": 271},
{"description": "A gradio web UI for running Large Language Models like LLaMA, llama.cpp, GPT-J, Pythia, OPT, and GALACTICA.", "language": "Python", "repo": "text-generation-webui", "new_stars": 581, "stars": 16312, "owner": "oobabooga", "forks": 2058},
{"description": "An API wrapper for Discord written in Python.", "language": "Python", "repo": "discord.py", "new_stars": 130, "stars": 13128, "owner": "Rapptz", "forks": 3730},
{"description": "You like pytorch? You like micrograd? You love tinygrad!", "language": "Python", "repo": "tinygrad", "new_stars": 1112, "stars": 15366, "owner": "geohot", "forks": 1676},
{"description": "Learn how to design large-scale systems. Prep for the system design interview. Includes Anki flashcards.", "language": "Python", "repo": "system-design-primer", "new_stars": 590, "stars": 223132, "owner": "donnemartin", "forks": 39505},
{"description": "Auto1111 extension implementing text2video diffusion models (like ModelScope or VideoCrafter) using only Auto1111 webui dependencies", "language": "Python", "repo": "sd-webui-text2video", "new_stars": 90, "stars": 860, "owner": "kabachuha", "forks": 57},
{"description": "Fine-tuning LLaMA with PEFT (PT+SFT+RLHF with QLoRA)", "language": "Python", "repo": "LLaMA-Efficient-Tuning", "new_stars": 151, "stars": 990, "owner": "hiyouga", "forks": 480},
{"description": "Fine-tuning ChatGLM-6B with PEFT | \u57fa\u4e8e PEFT \u7684\u9ad8\u6548 ChatGLM \u5fae\u8c03", "language": "Python", "repo": "ChatGLM-Efficient-Tuning", "new_stars": 195, "stars": 1543, "owner": "hiyouga", "forks": 181}
]