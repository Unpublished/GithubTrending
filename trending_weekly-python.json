[
{"description": "Specify what you want it to build, the AI asks for clarification, and then builds it.", "language": "Python", "repo": "gpt-engineer", "new_stars": 7623, "stars": 34210, "owner": "AntonOsika", "forks": 5687},
{"description": "Infinite Photorealistic Worlds using Procedural Generation", "language": "Python", "repo": "infinigen", "new_stars": 967, "stars": 3614, "owner": "princeton-vl", "forks": 365},
{"description": "Official Code for DragGAN (SIGGRAPH 2023)", "language": "Python", "repo": "DragGAN", "new_stars": 8721, "stars": 26840, "owner": "XingangPan", "forks": 2599},
{"description": "Open platform for operating LLMs in production", "language": "Python", "repo": "OpenLLM", "new_stars": 1102, "stars": 4573, "owner": "bentoml", "forks": 286},
{"description": "Unified AI", "language": "Python", "repo": "ivy", "new_stars": 322, "stars": 11620, "owner": "unifyai", "forks": 4486},
{"description": "WebGLM: An Efficient Web-enhanced Question Answering System (KDD 2023)", "language": "Python", "repo": "WebGLM", "new_stars": 383, "stars": 826, "owner": "THUDM", "forks": 78},
{"description": "A more memory-efficient rewrite of the HF transformers implementation of Llama for use with quantized weights.", "language": "Python", "repo": "exllama", "new_stars": 241, "stars": 802, "owner": "turboderp", "forks": 83},
{"description": "An Extensible Toolkit for Finetuning and Inference of Large Foundation Models. Large Model for All.", "language": "Python", "repo": "LMFlow", "new_stars": 566, "stars": 6625, "owner": "OptimalScale", "forks": 976},
{"description": "roop extension for StableDiffusion web-ui", "language": "Python", "repo": "sd-webui-roop", "new_stars": 719, "stars": 1021, "owner": "s0md3v", "forks": 231},
{"description": "Official PyTorch implementation of StyleGAN3", "language": "Python", "repo": "stylegan3", "new_stars": 258, "stars": 5528, "owner": "NVlabs", "forks": 976},
{"description": "Family of instruction-following LLMs powered by Evol-Instruct: WizardLM, WizardCoder", "language": "Python", "repo": "WizardLM", "new_stars": 440, "stars": 3516, "owner": "nlpxucan", "forks": 255},
{"description": "scikit-learn: machine learning in Python", "language": "Python", "repo": "scikit-learn", "new_stars": 269, "stars": 54918, "owner": "scikit-learn", "forks": 24405},
{"description": "High-Resolution Image Synthesis with Latent Diffusion Models", "language": "Python", "repo": "stablediffusion", "new_stars": 789, "stars": 25929, "owner": "Stability-AI", "forks": 3298},
{"description": "Label, clean and enrich text datasets with LLMs. Discord:", "language": "Python", "repo": "autolabel", "new_stars": 377, "stars": 942, "owner": "refuel-ai", "forks": 52},
{"description": "H2O LLM Studio - a framework and no-code GUI for fine-tuning LLMs", "language": "Python", "repo": "h2o-llmstudio", "new_stars": 178, "stars": 1970, "owner": "h2oai", "forks": 177},
{"description": "LLM training code for MosaicML foundation models", "language": "Python", "repo": "llm-foundry", "new_stars": 211, "stars": 2456, "owner": "mosaicml", "forks": 235},
{"description": "NVR with realtime local object detection for IP cameras", "language": "Python", "repo": "frigate", "new_stars": 101, "stars": 8534, "owner": "blakeblackshear", "forks": 862},
{"description": "Train neural networks up to 7x faster", "language": "Python", "repo": "composer", "new_stars": 121, "stars": 3825, "owner": "mosaicml", "forks": 274},
{"description": "A gradio web UI for running Large Language Models like LLaMA, llama.cpp, GPT-J, Pythia, OPT, and GALACTICA.", "language": "Python", "repo": "text-generation-webui", "new_stars": 581, "stars": 16328, "owner": "oobabooga", "forks": 2059},
{"description": "An API wrapper for Discord written in Python.", "language": "Python", "repo": "discord.py", "new_stars": 130, "stars": 13129, "owner": "Rapptz", "forks": 3731},
{"description": "You like pytorch? You like micrograd? You love tinygrad!", "language": "Python", "repo": "tinygrad", "new_stars": 1112, "stars": 15373, "owner": "geohot", "forks": 1677},
{"description": "Learn how to design large-scale systems. Prep for the system design interview. Includes Anki flashcards.", "language": "Python", "repo": "system-design-primer", "new_stars": 590, "stars": 223149, "owner": "donnemartin", "forks": 39509},
{"description": "Auto1111 extension implementing text2video diffusion models (like ModelScope or VideoCrafter) using only Auto1111 webui dependencies", "language": "Python", "repo": "sd-webui-text2video", "new_stars": 90, "stars": 866, "owner": "kabachuha", "forks": 58},
{"description": "Fine-tuning LLaMA with PEFT (PT+SFT+RLHF with QLoRA)", "language": "Python", "repo": "LLaMA-Efficient-Tuning", "new_stars": 151, "stars": 1007, "owner": "hiyouga", "forks": 481},
{"description": "Fine-tuning ChatGLM-6B with PEFT | \u57fa\u4e8e PEFT \u7684\u9ad8\u6548 ChatGLM \u5fae\u8c03", "language": "Python", "repo": "ChatGLM-Efficient-Tuning", "new_stars": 195, "stars": 1554, "owner": "hiyouga", "forks": 183}
]