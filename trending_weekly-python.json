[
{"description": "gpt4all: an ecosystem of open-source chatbots trained on a massive collections of clean assistant data including code, stories and dialogue", "language": "Python", "repo": "gpt4all", "new_stars": 10815, "stars": 24759, "owner": "nomic-ai", "forks": 2526},
{"description": "\u79d1\u7814\u5de5\u4f5c\u4e13\u7528ChatGPT\u62d3\u5c55\uff0c\u7279\u522b\u4f18\u5316\u5b66\u672fPaper\u6da6\u8272\u4f53\u9a8c\uff0c\u652f\u6301\u81ea\u5b9a\u4e49\u5feb\u6377\u6309\u94ae\uff0c\u652f\u6301\u81ea\u5b9a\u4e49\u51fd\u6570\u63d2\u4ef6\uff0c\u652f\u6301markdown\u8868\u683c\u663e\u793a\uff0cTex\u516c\u5f0f\u53cc\u663e\u793a\uff0c\u4ee3\u7801\u663e\u793a\u529f\u80fd\u5b8c\u5584\uff0c\u65b0\u589e\u672c\u5730Python/C++/Go\u9879\u76ee\u6811\u5256\u6790\u529f\u80fd/\u9879\u76ee\u6e90\u4ee3\u7801\u81ea\u8bd1\u89e3\u80fd\u529b\uff0c\u65b0\u589ePDF\u548cWord\u6587\u732e\u6279\u91cf\u603b\u7ed3\u529f\u80fd/PDF\u8bba\u6587\u5168\u6587\u7ffb\u8bd1\u529f\u80fd", "language": "Python", "repo": "chatgpt_academic", "new_stars": 7978, "stars": 23712, "owner": "binary-husky", "forks": 2603},
{"description": "Fine-tuning LLaMA to follow instructions within 1 Hour and 1.2M Parameters", "language": "Python", "repo": "LLaMA-Adapter", "new_stars": 885, "stars": 2019, "owner": "ZrrSkywalker", "forks": 120},
{"description": "Build and control your own LLMs", "language": "Python", "repo": "xturing", "new_stars": 788, "stars": 1241, "owner": "stochasticai", "forks": 83},
{"description": "Making large AI models cheaper, faster and more accessible", "language": "Python", "repo": "ColossalAI", "new_stars": 2605, "stars": 27233, "owner": "hpcaitech", "forks": 3100},
{"description": "Building applications with LLMs through composability", "language": "Python", "repo": "langchain", "new_stars": 3895, "stars": 22557, "owner": "hwchase17", "forks": 2083},
{"description": "An open-source framework for training large multimodal models", "language": "Python", "repo": "open_flamingo", "new_stars": 403, "stars": 1515, "owner": "mlfoundations", "forks": 89},
{"description": "Implementation of the LLaMA language model based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed.", "language": "Python", "repo": "lit-llama", "new_stars": 627, "stars": 2182, "owner": "Lightning-AI", "forks": 104},
{"description": "Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.", "language": "Python", "repo": "transformers", "new_stars": 2176, "stars": 91225, "owner": "huggingface", "forks": 19338},
{"description": "Build voice-based LLM agents. Modular + open source.", "language": "Python", "repo": "vocode-python", "new_stars": 396, "stars": 937, "owner": "vocodedev", "forks": 48},
{"description": "something like visual-chatgpt, \u6587\u5fc3\u4e00\u8a00\u7684\u5f00\u6e90\u7248", "language": "Python", "repo": "visual-openllm", "new_stars": 172, "stars": 704, "owner": "visual-openllm", "forks": 66},
{"description": null, "language": "Python", "repo": "ChatDoctor", "new_stars": 671, "stars": 2152, "owner": "Kent0n-Li", "forks": 226},
{"description": "\u3010\u7f16\u7a0b\u968f\u60f3\u3011\u6574\u7406\u7684\u300a\u592a\u5b50\u515a\u5173\u7cfb\u7f51\u7edc\u300b\uff0c\u4e13\u95e8\u63ed\u9732\u8d75\u56fd\u7684\u6743\u8d35", "language": "Python", "repo": "zhao", "new_stars": 267, "stars": 12317, "owner": "programthink", "forks": 2763},
{"description": "the open source embedding database", "language": "Python", "repo": "chroma", "new_stars": 486, "stars": 1729, "owner": "chroma-core", "forks": 95},
{"description": "PEFT: State-of-the-art Parameter-Efficient Fine-Tuning.", "language": "Python", "repo": "peft", "new_stars": 546, "stars": 3409, "owner": "huggingface", "forks": 218},
{"description": "Enjoy reading with your favorite style.", "language": "Python", "repo": "ebook-GPT-translator", "new_stars": 184, "stars": 767, "owner": "jesselau76", "forks": 84},
{"description": "Python - 100\u5929\u4ece\u65b0\u624b\u5230\u5927\u5e08", "language": "Python", "repo": "Python-100-Days", "new_stars": 481, "stars": 132756, "owner": "jackfrued", "forks": 48538},
{"description": "Stable Diffusion with Core ML on Apple Silicon", "language": "Python", "repo": "ml-stable-diffusion", "new_stars": 4385, "stars": 10595, "owner": "apple", "forks": 471},
{"description": "\u4e2d\u6587LLaMA&Alpaca\u5927\u8bed\u8a00\u6a21\u578b+\u672c\u5730\u90e8\u7f72 (Chinese LLaMA & Alpaca LLMs)", "language": "Python", "repo": "Chinese-LLaMA-Alpaca", "new_stars": 2105, "stars": 3288, "owner": "ymcui", "forks": 291},
{"description": "A batteries-included library for building AI-powered software", "language": "Python", "repo": "marvin", "new_stars": 811, "stars": 1445, "owner": "PrefectHQ", "forks": 55},
{"description": "\u514d\u8d39\u7684 ChatGPT \u955c\u50cf\u7f51\u7ad9\u5217\u8868\uff0c\u6301\u7eed\u66f4\u65b0\u3002List of free ChatGPT mirror sites, continuously updated.", "language": "Python", "repo": "awesome-free-chatgpt", "new_stars": 611, "stars": 950, "owner": "LiLittleCat", "forks": 66},
{"description": "A command-line productivity tool powered by ChatGPT, will help you accomplish your tasks faster and more efficiently.", "language": "Python", "repo": "shell_gpt", "new_stars": 412, "stars": 3943, "owner": "TheR1D", "forks": 239},
{"description": "A collective list of free APIs", "language": "Python", "repo": "public-apis", "new_stars": 2411, "stars": 234984, "owner": "public-apis", "forks": 26692},
{"description": "Learn how to design large-scale systems. Prep for the system design interview. Includes Anki flashcards.", "language": "Python", "repo": "system-design-primer", "new_stars": 1538, "stars": 217038, "owner": "donnemartin", "forks": 38580},
{"description": "CodeGeeX: An Open Multilingual Code Generation Model", "language": "Python", "repo": "CodeGeeX", "new_stars": 333, "stars": 3941, "owner": "THUDM", "forks": 259}
]