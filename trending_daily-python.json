[
{"description": "Advanced Python Mastery (course by", "language": "Python", "repo": "python-mastery", "new_stars": 2589, "stars": 5107, "owner": "dabeaz-course", "forks": 563},
{"description": "Examples and recipes for Llama 2 model", "language": "Python", "repo": "llama-recipes", "new_stars": 244, "stars": 1054, "owner": "facebookresearch", "forks": 111},
{"description": "A gradio web UI for running Large Language Models like LLaMA, llama.cpp, GPT-J, Pythia, OPT, and GALACTICA.", "language": "Python", "repo": "text-generation-webui", "new_stars": 159, "stars": 18354, "owner": "oobabooga", "forks": 2335},
{"description": "Open source implementation of the ChatGPT Code Interpreter", "language": "Python", "repo": "codeinterpreter-api", "new_stars": 485, "stars": 1441, "owner": "shroominic", "forks": 121},
{"description": "Evals is a framework for evaluating LLMs and LLM systems, and an open-source registry of benchmarks.", "language": "Python", "repo": "evals", "new_stars": 31, "stars": 11265, "owner": "openai", "forks": 2188},
{"description": "Inference code for LLaMA models", "language": "Python", "repo": "llama", "new_stars": 2020, "stars": 30899, "owner": "facebookresearch", "forks": 4890},
{"description": "LLaMA v2 Chatbot", "language": "Python", "repo": "llama2-chatbot", "new_stars": 156, "stars": 634, "owner": "a16z-infra", "forks": 86},
{"description": "Scale LLM Engine public repository", "language": "Python", "repo": "llm-engine", "new_stars": 67, "stars": 296, "owner": "scaleapi", "forks": 14},
{"description": "Run large language models at home, BitTorrent-style. Fine-tuning and inference up to 10x faster than offloading", "language": "Python", "repo": "petals", "new_stars": 247, "stars": 5944, "owner": "bigscience-workshop", "forks": 252},
{"description": "Fast and memory-efficient exact attention", "language": "Python", "repo": "flash-attention", "new_stars": 186, "stars": 5293, "owner": "Dao-AILab", "forks": 418},
{"description": "ShortGPT - An experimental AI framework for automated short/video content creation. Enables creators to rapidly produce, manage, and deliver content using AI and automation.", "language": "Python", "repo": "ShortGPT", "new_stars": 268, "stars": 1234, "owner": "RayVentura", "forks": 105},
{"description": "Enable everyone to develop, optimize and deploy AI models natively on everyone's devices.", "language": "Python", "repo": "mlc-llm", "new_stars": 133, "stars": 10764, "owner": "mlc-ai", "forks": 742},
{"description": "langchain-ChatGLM, local knowledge based ChatGLM with langchain \uff5c \u57fa\u4e8e\u672c\u5730\u77e5\u8bc6\u5e93\u7684 ChatGLM \u95ee\u7b54", "language": "Python", "repo": "langchain-ChatGLM", "new_stars": 98, "stars": 12344, "owner": "imClumsyPanda", "forks": 1939},
{"description": "Faster Whisper transcription with CTranslate2", "language": "Python", "repo": "faster-whisper", "new_stars": 163, "stars": 3546, "owner": "guillaumekln", "forks": 246},
{"description": "the AI-native open-source embedding database", "language": "Python", "repo": "chroma", "new_stars": 54, "stars": 7398, "owner": "chroma-core", "forks": 511},
{"description": "Large-scale Self-supervised Pre-training Across Tasks, Languages, and Modalities", "language": "Python", "repo": "unilm", "new_stars": 162, "stars": 14261, "owner": "microsoft", "forks": 2011},
{"description": "Sweep is an AI junior developer", "language": "Python", "repo": "sweep", "new_stars": 67, "stars": 1135, "owner": "sweepai", "forks": 51},
{"description": "Fast Segment Anything", "language": "Python", "repo": "FastSAM", "new_stars": 24, "stars": 4932, "owner": "CASIA-IVA-Lab", "forks": 790},
{"description": "Train transformer language models with reinforcement learning.", "language": "Python", "repo": "trl", "new_stars": 92, "stars": 4169, "owner": "lvwerra", "forks": 452},
{"description": "GPT 3.5/4 with a Chat Web UI. No API key required.", "language": "Python", "repo": "freegpt-webui", "new_stars": 169, "stars": 3776, "owner": "ramonvc", "forks": 1115},
{"description": "Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.", "language": "Python", "repo": "transformers", "new_stars": 179, "stars": 108352, "owner": "huggingface", "forks": 21529},
{"description": "AutoChain: Build lightweight, extensible, and testable LLM Agents", "language": "Python", "repo": "AutoChain", "new_stars": 131, "stars": 705, "owner": "Forethought-Technologies", "forks": 22},
{"description": "A more memory-efficient rewrite of the HF transformers implementation of Llama for use with quantized weights.", "language": "Python", "repo": "exllama", "new_stars": 47, "stars": 1245, "owner": "turboderp", "forks": 158},
{"description": "A sample app for the Retrieval-Augmented Generation pattern running in Azure, using Azure Cognitive Search for retrieval and Azure OpenAI large language models to power ChatGPT-style and Q&A experiences.", "language": "Python", "repo": "azure-search-openai-demo", "new_stars": 15, "stars": 2982, "owner": "Azure-Samples", "forks": 1673},
{"description": "\u4e2d\u6587LLaMA&Alpaca\u5927\u8bed\u8a00\u6a21\u578b+\u672c\u5730CPU/GPU\u8bad\u7ec3\u90e8\u7f72 (Chinese LLaMA & Alpaca LLMs)", "language": "Python", "repo": "Chinese-LLaMA-Alpaca", "new_stars": 122, "stars": 12984, "owner": "ymcui", "forks": 1368}
]