[
{"description": "<", "language": "Python", "repo": "SuperAGI", "new_stars": 7985, "stars": 9801, "owner": "TransformerOptimus", "forks": 1054},
{"description": "one-click deepfake (face swap)", "language": "Python", "repo": "roop", "new_stars": 6701, "stars": 14875, "owner": "s0md3v", "forks": 2656},
{"description": "Hackable implementation of state-of-the-art open-source LLMs based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed.", "language": "Python", "repo": "lit-gpt", "new_stars": 1251, "stars": 1548, "owner": "Lightning-AI", "forks": 142},
{"description": "You like pytorch? You like micrograd? You love tinygrad!", "language": "Python", "repo": "tinygrad", "new_stars": 3380, "stars": 17061, "owner": "geohot", "forks": 2053},
{"description": "Fine-tuning ChatGLM-6B with PEFT | \u57fa\u4e8e PEFT \u7684\u9ad8\u6548 ChatGLM \u5fae\u8c03", "language": "Python", "repo": "ChatGLM-Efficient-Tuning", "new_stars": 827, "stars": 1914, "owner": "hiyouga", "forks": 273},
{"description": "Large Language Model Text Generation Inference", "language": "Python", "repo": "text-generation-inference", "new_stars": 1053, "stars": 2658, "owner": "huggingface", "forks": 239},
{"description": "Book_4_\u300a\u77e9\u9635\u529b\u91cf\u300b | \u9e22\u5c3e\u82b1\u4e66\uff1a\u4ece\u52a0\u51cf\u4e58\u9664\u5230\u673a\u5668\u5b66\u4e60\uff1b\u4e0a\u67b6\uff01", "language": "Python", "repo": "Book4_Power-of-Matrix", "new_stars": 1180, "stars": 4034, "owner": "Visualize-ML", "forks": 563},
{"description": "Join us at H2O.ai to make the world's best open-source GPT with document and image Q&A, 100% private chat, no data leaks, Apache 2.0", "language": "Python", "repo": "h2ogpt", "new_stars": 1452, "stars": 3362, "owner": "h2oai", "forks": 316},
{"description": "Family of instruction-following LLMs powered by Evol-Instruct: WizardLM, WizardCoder", "language": "Python", "repo": "WizardLM", "new_stars": 1778, "stars": 3668, "owner": "nlpxucan", "forks": 271},
{"description": "Unified AI", "language": "Python", "repo": "ivy", "new_stars": 829, "stars": 11751, "owner": "unifyai", "forks": 4559},
{"description": "Voice data <= 10 mins can also be used to train a good VC model!", "language": "Python", "repo": "Retrieval-based-Voice-Conversion-WebUI", "new_stars": 2496, "stars": 6440, "owner": "RVC-Project", "forks": 922},
{"description": "Train neural networks up to 7x faster", "language": "Python", "repo": "composer", "new_stars": 703, "stars": 4224, "owner": "mosaicml", "forks": 306},
{"description": "langchain-ChatGLM, local knowledge based ChatGLM with langchain \uff5c \u57fa\u4e8e\u672c\u5730\u77e5\u8bc6\u5e93\u7684 ChatGLM \u95ee\u7b54", "language": "Python", "repo": "langchain-ChatGLM", "new_stars": 3032, "stars": 11017, "owner": "imClumsyPanda", "forks": 1703},
{"description": "FastAPI framework, high performance, easy to learn, fast to code, ready for production", "language": "Python", "repo": "fastapi", "new_stars": 1339, "stars": 59918, "owner": "tiangolo", "forks": 5008},
{"description": "An easy-to-use LLMs quantization package with user-friendly apis, based on GPTQ algorithm.", "language": "Python", "repo": "AutoGPTQ", "new_stars": 492, "stars": 1038, "owner": "PanQiWei", "forks": 107},
{"description": "\ud83d\ude80 A simple way to train and use PyTorch models with multi-GPU, TPU, mixed-precision", "language": "Python", "repo": "accelerate", "new_stars": 395, "stars": 5131, "owner": "huggingface", "forks": 545},
{"description": "Official Code for DragGAN (SIGGRAPH 2023)", "language": "Python", "repo": "DragGAN", "new_stars": 14812, "stars": 29654, "owner": "XingangPan", "forks": 3199},
{"description": "FlagAI (Fast LArge-scale General AI models) is a fast, easy-to-use and extensible toolkit for large-scale model.", "language": "Python", "repo": "FlagAI", "new_stars": 2056, "stars": 3309, "owner": "FlagAI-Open", "forks": 471},
{"description": "WhisperX: Automatic Speech Recognition with Word-level Timestamps (& Diarization)", "language": "Python", "repo": "whisperX", "new_stars": 611, "stars": 3686, "owner": "m-bain", "forks": 313},
{"description": "[SIGGRAPH Asia 2022] VideoReTalking: Audio-based Lip Synchronization for Talking Head Video Editing In the Wild", "language": "Python", "repo": "video-retalking", "new_stars": 310, "stars": 970, "owner": "OpenTalker", "forks": 172},
{"description": "A list of useful payloads and bypass for Web Application Security and Pentest/CTF", "language": "Python", "repo": "PayloadsAllTheThings", "new_stars": 827, "stars": 48928, "owner": "swisskyrepo", "forks": 12832},
{"description": "Synapse: Matrix homeserver written in Python/Twisted.", "language": "Python", "repo": "synapse", "new_stars": 140, "stars": 11033, "owner": "matrix-org", "forks": 2057},
{"description": "Ray is a unified framework for scaling AI and Python applications. Ray consists of a core distributed runtime and a toolkit of libraries (Ray AIR) for accelerating ML workloads.", "language": "Python", "repo": "ray", "new_stars": 598, "stars": 26439, "owner": "ray-project", "forks": 4933},
{"description": "Chat with your documents on your local device using GPT models. No data leaves your device and 100% private.", "language": "Python", "repo": "localGPT", "new_stars": 5512, "stars": 9604, "owner": "PromtEngineer", "forks": 917},
{"description": "An Extensible Toolkit for Finetuning and Inference of Large Foundation Models. Large Models for All.", "language": "Python", "repo": "LMFlow", "new_stars": 1344, "stars": 6783, "owner": "OptimalScale", "forks": 989}
]